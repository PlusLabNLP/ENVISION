{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c30050a",
   "metadata": {},
   "source": [
    "# Make TREK-150 Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2de5281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import csv, os, sys, re, string, json, glob, shutil, random, math, pprint, ast, pickle\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML as html_print\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# from IPython.display import Image\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from ipywidgets import Video\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%pylab inline\n",
    "\n",
    "import re\n",
    "from IPython.display import Image as ipy_Image\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ab2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our own built-in customized COCO API.\n",
    "sys.path.insert(0, \"../cocoapi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad7b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO API at:     /home/telinwu/research/project_jarvis/all_visualizations/../cocoapi/PythonAPI/pycocotools/coco.py\n",
      "COCOeval API at: /home/telinwu/research/project_jarvis/all_visualizations/../cocoapi/PythonAPI/pycocotools/cocoeval.py\n"
     ]
    }
   ],
   "source": [
    "# from pycocotools.coco import COCO\n",
    "# from pycocotools.cocoeval import COCOeval\n",
    "from PythonAPI.pycocotools.coco import COCO\n",
    "from PythonAPI.pycocotools.cocoeval import COCOeval\n",
    "\n",
    "import inspect\n",
    "print(\"COCO API at:     {}\".format(inspect.getfile(COCO)))\n",
    "print(\"COCOeval API at: {}\".format(inspect.getfile(COCOeval)))\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d0f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gt_pred_match_on_file(\n",
    "    coco_gt_file,\n",
    "    coco_pred_file,\n",
    "):\n",
    "    print(\"Checking GT and Pred files matching...\")\n",
    "    if type(coco_gt_file) is str:\n",
    "        coco_gt_data = json.load(open(coco_gt_file))\n",
    "    else:\n",
    "        coco_gt_data = coco_gt_file\n",
    "    if type(coco_pred_file) is str:\n",
    "        coco_pred_data = json.load(open(coco_pred_file))\n",
    "    elif type(coco_pred_file) == np.ndarray:\n",
    "        _coco = COCO(verbose=False)\n",
    "        coco_pred_data = _coco.loadNumpyAnnotations(coco_pred_file)\n",
    "    else:\n",
    "        coco_pred_data = coco_pred_file\n",
    "    gt_image_ids = {x[\"id\"]: True for x in coco_gt_data[\"images\"]}\n",
    "    pred_image_ids = [x[\"image_id\"] for x in coco_pred_data]\n",
    "    pred_image_ids = list(set(pred_image_ids))\n",
    "    for _id in pred_image_ids:\n",
    "        if _id not in gt_image_ids:\n",
    "            raise ValueError(\n",
    "                \"\\nGT file: {}\\nPred file: {}\\nThey do not match!?\".format(coco_gt_file, coco_pred_file))\n",
    "        pass\n",
    "    print(\"Checking complete!\")\n",
    "    pass  # Passed.\n",
    "\n",
    "\n",
    "def naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file,\n",
    "    coco_pred_file,\n",
    "    original_coco_gt_file=None,\n",
    "    top_k=None,\n",
    "    ignore_summaries=None,\n",
    "    verbose=False,\n",
    "):  \n",
    "    if original_coco_gt_file is not None:\n",
    "        coco_gt = COCO(annotation_file=original_coco_gt_file, verbose=verbose)\n",
    "        coco_gt = coco_gt.loadRes(coco_gt_file)\n",
    "        check_gt_pred_match_on_file(original_coco_gt_file, coco_pred_file)\n",
    "    else:\n",
    "        coco_gt = COCO(annotation_file=coco_gt_file, verbose=verbose)\n",
    "        check_gt_pred_match_on_file(coco_gt_file, coco_pred_file)\n",
    "    coco_dt = coco_gt.loadRes(coco_pred_file)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "    coco_eval.params.verbose = verbose\n",
    "    if top_k is not None:\n",
    "        coco_eval.params.maxDets = [top_k, top_k, top_k]\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize(ignore_summaries=ignore_summaries)\n",
    "    return coco_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "59ba242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_trek150_video(\n",
    "    video_id,\n",
    "    trek150_data_root=\"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150\",\n",
    "    frame_num_step=10,\n",
    "    image_id_accum=0,\n",
    "    annot_id_accum=0,\n",
    "    coco_format_images=[],\n",
    "    coco_format_annots=[],\n",
    "    narrations_info_dict=None,\n",
    "    token_positive_method=None,\n",
    "    action_class_mappings=None,\n",
    "    per_video_start_frames=None,\n",
    "    verbose=False,\n",
    "):\n",
    "    video_dir = os.path.join(trek150_data_root, video_id)\n",
    "    assert os.path.exists(video_dir)\n",
    "    frames_file = os.path.join(video_dir, \"frames.txt\")\n",
    "    assert os.path.exists(frames_file)\n",
    "    frame_nums = open(frames_file).readlines()\n",
    "    frame_nums = [int(x.strip()) for x in frame_nums]\n",
    "    gt_bboxes_file = os.path.join(video_dir, \"groundtruth_rect.txt\")\n",
    "    gt_bboxes = open(gt_bboxes_file).readlines()\n",
    "    gt_bboxes = [[float(b) for b in x.strip().split(\",\")] for x in gt_bboxes]\n",
    "\n",
    "    assert len(gt_bboxes) == len(frame_nums)\n",
    "    \n",
    "    if narrations_info_dict is not None:\n",
    "        start_frame = frame_nums[0]\n",
    "        stop_frame = frame_nums[-1]\n",
    "        mid_frame = (start_frame + stop_frame) // 2\n",
    "        frame_narr = []\n",
    "        for narrations_info in narrations_info_dict:\n",
    "            start_fr, stop_fr, mid_fr, narr = narrations_info\n",
    "            diff_fr = abs(mid_frame - mid_fr)\n",
    "            overlapping = len(range( max(start_frame, start_fr), min(stop_frame, stop_fr)+1 ))\n",
    "            overlapping = overlapping / (stop_frame - start_frame + 1)\n",
    "            # frame_narr.append((diff_fr, start_fr, stop_fr, narr))\n",
    "            # First compute the overlapping, then the stop frame `prior` range.\n",
    "            frame_narr.append((-overlapping, abs(stop_fr-start_frame), start_fr, stop_fr, narr))\n",
    "        frame_narr = sorted(frame_narr)[:5]\n",
    "        frame_narr = [(x, y, z) for _, _, x, y, z in frame_narr]\n",
    "        caption = frame_narr[0][-1]\n",
    "        if verbose:\n",
    "            print(start_frame, stop_frame)\n",
    "            pprint.pprint(frame_narr)\n",
    "            print(caption)\n",
    "            raise\n",
    "        \n",
    "        action_target_file = os.path.join(video_dir, \"action_target.txt\")\n",
    "        assert os.path.exists(action_target_file)\n",
    "        action_targets = open(action_target_file).readlines()\n",
    "        action_targets = [int(x.strip()) for x in action_targets]\n",
    "        verb = action_targets[0]\n",
    "        act_noun, target_noun = action_targets[1], action_targets[2]\n",
    "        \n",
    "        if token_positive_method == \"gt\":\n",
    "            target_nouns_allowed = action_class_mappings[\"noun\"][target_noun]\n",
    "            tokens = caption.split(\" \")\n",
    "            begin_pos, end_pos = 0, 0\n",
    "            target_poss = []\n",
    "            gt_word_found = False\n",
    "            for token in tokens:\n",
    "                end_pos = begin_pos + len(token)\n",
    "                for target_noun_allowed in target_nouns_allowed:\n",
    "                    if (\n",
    "                        token == target_noun_allowed and\n",
    "                        [begin_pos, end_pos] not in target_poss\n",
    "                    ):\n",
    "                        target_poss.append([begin_pos, end_pos])\n",
    "                    elif \"-\" in target_noun_allowed:\n",
    "                        if (\n",
    "                            token == target_noun_allowed.split(\"-\")[0] or\n",
    "                            token == target_noun_allowed.split(\"-\")[1] and\n",
    "                            [begin_pos, end_pos] not in target_poss\n",
    "                        ):\n",
    "                            target_poss.append([begin_pos, end_pos])\n",
    "                    if target_noun_allowed in token:\n",
    "                        gt_word_found = True\n",
    "                begin_pos = end_pos + 1\n",
    "                pass\n",
    "            target_poss = sorted(target_poss)\n",
    "            tokens_positive = target_poss\n",
    "            if not gt_word_found:\n",
    "                print(caption)\n",
    "                print(target_nouns_allowed)\n",
    "                print(action_targets)\n",
    "                print(start_frame, stop_frame)\n",
    "                pprint.pprint(frame_narr)\n",
    "                print(video_id)\n",
    "                caption = action_class_mappings[\"verb\"][verb][0] \\\n",
    "                    + \" \" + action_class_mappings[\"noun\"][target_noun][0]\n",
    "                print(caption)\n",
    "                begin_pos = len(action_class_mappings[\"verb\"][verb][0]) + 1\n",
    "                end_pos = begin_pos + len(action_class_mappings[\"noun\"][target_noun][0])\n",
    "                target_poss.append([begin_pos, end_pos])\n",
    "                print(target_poss)\n",
    "                print(\"-\"*50)\n",
    "                # raise\n",
    "        # raise\n",
    "\n",
    "    frame_num_idx = 0\n",
    "    while frame_num_idx < len(frame_nums):\n",
    "        # Per video start frame.\n",
    "        if (\n",
    "            per_video_start_frames is not None\n",
    "            and per_video_start_frames[video_id] is not None\n",
    "            and frame_nums[frame_num_idx] < per_video_start_frames[video_id]\n",
    "        ):\n",
    "            frame_num_idx += 1\n",
    "            continue\n",
    "        if (\n",
    "            per_video_start_frames is not None\n",
    "            and frame_nums[frame_num_idx] == per_video_start_frames[video_id]\n",
    "        ):\n",
    "            print(\"Saved {} frames out of {} frames.\".format(frame_num_idx, len(frame_nums)))\n",
    "        \n",
    "        if frame_num_idx >= len(frame_nums):\n",
    "            break\n",
    "        gt_bbox = gt_bboxes[frame_num_idx]\n",
    "        while sum(gt_bbox) == -4:  # [-1, -1, -1, -1] no bbox case!\n",
    "            if frame_num_idx >= len(frame_nums):\n",
    "                break\n",
    "            frame_num_idx += 1 # Just skip these frames!\n",
    "            gt_bbox = gt_bboxes[frame_num_idx]\n",
    "        if frame_num_idx >= len(frame_nums):\n",
    "            break\n",
    "        \n",
    "        bbx, bby, bbh, bbw = gt_bbox\n",
    "        frame_num = frame_nums[frame_num_idx]\n",
    "        img_path = os.path.join(video_dir, \"img\", \"frame_{:010d}.jpg\".format(frame_num))\n",
    "        file_name = os.path.join(video_id, \"img\", \"frame_{:010d}.jpg\".format(frame_num))\n",
    "        assert os.path.exists(img_path)\n",
    "        frame_image = Image.open(img_path)\n",
    "        width, height = frame_image.size\n",
    "        \n",
    "        if narrations_info_dict is None:\n",
    "            caption = \"object_of_change\"\n",
    "            tokens_positive_eval = [[[0, 16]]]\n",
    "            tokens_positive = [[0, 16]]\n",
    "        else:\n",
    "            if len(tokens_positive) == 0:\n",
    "                tokens_positive = [[0, len(caption)]]\n",
    "            tokens_positive_eval = [tokens_positive]\n",
    "        \n",
    "        image_dict = {\n",
    "            \"file_name\": file_name,\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "            \"id\": image_id_accum,\n",
    "            \"caption\": caption,\n",
    "            \"tokens_positive_eval\": tokens_positive_eval,\n",
    "        }\n",
    "        coco_format_images.append(image_dict)\n",
    "        annot_dict = {\n",
    "            \"segmentation\": [],\n",
    "            \"area\": bbh * bbw,\n",
    "            \"iscrowd\": 0,\n",
    "            \"ignore\": 0,\n",
    "            \"image_id\": image_id_accum,\n",
    "            \"bbox\": gt_bbox,\n",
    "            \"category_id\": 1,\n",
    "            \"id\": annot_id_accum,\n",
    "            \"tokens_positive\": tokens_positive,\n",
    "        }\n",
    "        coco_format_annots.append(annot_dict)\n",
    "        \n",
    "        annot_id_accum += 1\n",
    "        image_id_accum += 1\n",
    "        frame_num_idx += frame_num_step\n",
    "\n",
    "    return image_id_accum, annot_id_accum\n",
    "\n",
    "\n",
    "def tracking_to_od_results_on_one_video(\n",
    "    video_id,\n",
    "    trek150_data_root=\"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150\",\n",
    "    pred_root=\"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150/LTMU-H/ope\",\n",
    "    frame_num_step=10,\n",
    "    image_id_accum=0,\n",
    "    coco_format_preds=[],\n",
    "):\n",
    "    video_dir = os.path.join(trek150_data_root, video_id)\n",
    "    assert os.path.exists(video_dir)\n",
    "    frames_file = os.path.join(video_dir, \"frames.txt\")\n",
    "    assert os.path.exists(frames_file)\n",
    "    frame_nums = open(frames_file).readlines()\n",
    "    frame_nums = [int(x.strip()) for x in frame_nums]\n",
    "    gt_bboxes_file = os.path.join(video_dir, \"groundtruth_rect.txt\")\n",
    "    gt_bboxes = open(gt_bboxes_file).readlines()\n",
    "    gt_bboxes = [[float(b) for b in x.strip().split(\",\")] for x in gt_bboxes]\n",
    "    preds_file = os.path.join(pred_root, \"{}.txt\".format(video_id))\n",
    "    assert os.path.exists(preds_file)\n",
    "    pred_bboxes = open(preds_file).readlines()\n",
    "    pred_bboxes = [[float(b) for b in x.strip().split(\",\")] for x in pred_bboxes]\n",
    "\n",
    "    assert len(gt_bboxes) == len(frame_nums) == len(pred_bboxes)\n",
    "\n",
    "    frame_num_idx = 0\n",
    "    while frame_num_idx < len(frame_nums):\n",
    "        if frame_num_idx >= len(frame_nums):\n",
    "            break\n",
    "        gt_bbox = gt_bboxes[frame_num_idx]\n",
    "        while sum(gt_bbox) == -4:  # [-1, -1, -1, -1] no bbox case!\n",
    "            if frame_num_idx >= len(frame_nums):\n",
    "                break\n",
    "            frame_num_idx += 1 # Just skip these frames!\n",
    "            gt_bbox = gt_bboxes[frame_num_idx]\n",
    "        if frame_num_idx >= len(frame_nums):\n",
    "            break\n",
    "\n",
    "        pred_dict = {\n",
    "            \"image_id\": image_id_accum,\n",
    "            \"category_id\": 1,\n",
    "            \"bbox\": pred_bboxes[frame_num_idx],\n",
    "            \"score\": 1.0,\n",
    "        }\n",
    "        coco_format_preds.append(pred_dict)\n",
    "\n",
    "        image_id_accum += 1\n",
    "        frame_num_idx += frame_num_step\n",
    "\n",
    "    return image_id_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1865eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trek150_data_root = \"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150\"\n",
    "video_id_file = os.path.join(os.path.join(trek150_data_root, \"sequences.txt\"))\n",
    "\n",
    "video_ids = []\n",
    "for line in open(video_id_file):\n",
    "    video_ids.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d59149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...: 100%|█████████████████████████████████████████████████████████████████████████████████| 150/150 [00:03<00:00, 40.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9589 9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inits.\n",
    "image_id_accum = 0\n",
    "annot_id_accum = 0\n",
    "frame_num_step = 10\n",
    "coco_format_images = []\n",
    "coco_format_annots = []\n",
    "\n",
    "for video_id in tqdm(video_ids, desc=\"Processing TREK-150 Videos...\"):\n",
    "    image_id_accum, annot_id_accum = process_one_trek150_video(\n",
    "        video_id=video_id,\n",
    "        trek150_data_root=\"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150\",\n",
    "        frame_num_step=frame_num_step,\n",
    "        image_id_accum=image_id_accum,\n",
    "        annot_id_accum=annot_id_accum,\n",
    "        coco_format_images=coco_format_images,\n",
    "        coco_format_annots=coco_format_annots,\n",
    "        narrations_info_dict=None,\n",
    "        token_positive_method=None,\n",
    "        action_class_mappings=None,\n",
    "        per_video_start_frames=None,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "print(len(coco_format_images), len(coco_format_annots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e0848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_coco_file(\n",
    "    coco_format_images,\n",
    "    coco_format_annots,\n",
    "    output_root=\"/local1/telinwu/research/resources/TREK-150/coco_annotations\",\n",
    "    output_name=None,\n",
    "):\n",
    "    output_coco_data = {\n",
    "        \"info\": {\n",
    "            \"description\": \"TREK-150 to COCO formatted dataset\",\n",
    "            \"version\": \"1.0.0\",\n",
    "            \"year\": 2023,\n",
    "            \"contributor\": \"Te-Lin Wu\",\n",
    "            \"date_created\": str(datetime.now()),\n",
    "            \"frame_num_step\": 10,\n",
    "            \"trek150_data_root\": trek150_data_root,\n",
    "        },\n",
    "        \"licenses\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
    "                \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
    "            }\n",
    "        ],\n",
    "        \"categories\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"object_of_change\",\n",
    "                \"supercategory\": \"object\"\n",
    "            }\n",
    "        ],\n",
    "        \"images\": coco_format_images,\n",
    "        \"annotations\": coco_format_annots,\n",
    "    }\n",
    "\n",
    "    output_to = (\n",
    "        \"{}\"\n",
    "        \"/{}.json\".format(output_root, output_name)\n",
    "    )\n",
    "\n",
    "    json.dump(\n",
    "        output_coco_data,\n",
    "        open(output_to, \"w\"),\n",
    "        indent=4,\n",
    "    )\n",
    "    \n",
    "    print(\"Saving coco file to: {}\".format(output_to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c6869c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving coco file to: /local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_stepwise_10_frames_od_only.json\n"
     ]
    }
   ],
   "source": [
    "save_coco_file(\n",
    "    coco_format_images,\n",
    "    coco_format_annots,\n",
    "    output_root=\"/local1/telinwu/research/resources/TREK-150/coco_annotations\",\n",
    "    output_name=\"trek150_stepwise_10_frames_od_only\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f38acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...: 100%|████████████████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 330.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inits.\n",
    "image_id_accum = 0\n",
    "frame_num_step = 10\n",
    "coco_format_preds = []\n",
    "\n",
    "for video_id in tqdm(video_ids, desc=\"Processing TREK-150 Videos...\"):\n",
    "    image_id_accum = tracking_to_od_results_on_one_video(\n",
    "        video_id,\n",
    "        trek150_data_root=\"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150\",\n",
    "        pred_root=\"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150/LTMU-H/ope\",\n",
    "        frame_num_step=frame_num_step,\n",
    "        image_id_accum=image_id_accum,\n",
    "        coco_format_preds=coco_format_preds,\n",
    "    )\n",
    "    \n",
    "print(len(coco_format_preds))\n",
    "outfile = \"/local1/telinwu/research/resources/TREK-150/baselines/LTMU-H/ope/trek150_stepwise_10.json\"\n",
    "json.dump(\n",
    "    coco_format_preds,\n",
    "    open(outfile, \"w\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171cc08",
   "metadata": {},
   "source": [
    "# Some Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a38ef355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.564\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=  1 ] = 0.409\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.495\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations\"\n",
    "    \"/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "    \"/ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma\"\n",
    "    \"/eval_ego4d_scod_val_finetuned_45K_on_TREK150_all_frames_new\"\n",
    "    \"/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=1,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74a45dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_stepwise_10_frames_od_only.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "    \"/LTMU-H/ope/trek150_stepwise_10.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=1,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ac973303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.77s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=  1 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_stepwise_10_frames_od_only.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "    \"/naive_scod_finetuning_v1/eval_ego4d_scod_val_finetuned_45K\"\n",
    "    \"/eval/model_0045000/inference/test/bbox.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=1,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3507fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_stepwise_10_frames_od_only.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "    \"/naive_scod_finetuning_large_v1/eval_ego4d_scod_val_finetuned_45K\"\n",
    "    \"/eval/model_0045000/inference/test/bbox.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=1,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9d5381eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.38s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.510\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=  1 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.471\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_stepwise_10_frames_od_only.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "    \"/narrated_scod_finetuning_large_v2/eval_ego4d_scod_val_finetuned_45K/\"\n",
    "    \"/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=1,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bdd60142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.412\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=  1 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.451\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.451\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.451\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_1st_frame_only_narrated_gt.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "    \"/narrated_scod_finetuning_large_v2/eval_ego4d_scod_val_finetuned_45K_on_TREK150_1st_frame_only/\"\n",
    "    \"/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=1,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "49f7b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.3791\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.5354\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.4012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.4487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.7180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.7783\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_stepwise_10_frames_od_only.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/bryanzhou008/jarvis/project_jarvis/baselines/ego4d-eccv2022-solutions/scod/TREK-150-test-1.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=None,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c6997d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.0000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.0000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.0000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.0000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.0000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.0000\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/paper_data\"\n",
    "    \"/narrated/gt_srl_arg1/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/bryanzhou008/jarvis/project_jarvis/baselines/ego4d-eccv2022-solutions/scod/TREK-150-test-all_frame.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=None,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61419e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=  1 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_1st_frame_only_narrated_gt.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/bryanzhou008/jarvis/project_jarvis/baselines\"\n",
    "    \"/ego4d-eccv2022-solutions/scod/TREK-150-test-first_frame.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=1,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "6cd8c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.2949\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.4147\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=  1 ] = 0.3085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.4500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.4500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.4500\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations\"\n",
    "    \"/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/bryanzhou008/jarvis/project_jarvis/baselines/ego4d-eccv2022-solutions\"\n",
    "    \"/scod/TREK-150-test-all_frame_complete.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=1,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe1f89",
   "metadata": {},
   "source": [
    "### Transforming COCO Results to TREK-150 Utilizable Input Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "071d5bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 9509400/9509400 [00:48<00:00, 194660.69it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations\"\n",
    "    \"/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "    \"/narrated_scod_finetuning_large_v2/eval_ego4d_scod_val_finetuned_45K_on_TREK150_all_frames\"\n",
    "    \"/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/bryanzhou008/jarvis/project_jarvis/baselines/ego4d-eccv2022-solutions/scod/TREK-150-test-1.json\"\n",
    ")\n",
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/paper_data\"\n",
    "    # \"/narrated/gpt_v1/gpt_trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    "    # \"/narrated/gpt_v2/gpt_trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    "    \"/narrated/gt_srl_arg1/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    ")\n",
    "\"\"\"\n",
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/coco_annotations\"\n",
    "    \"/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    ")\n",
    "\"\"\"\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "    # \"/ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma\"\n",
    "    # \"/eval_ego4d_scod_val_finetuned_65K_on_TREK150_all_frames\"\n",
    "    # \"/eval/model_0065000/inference/narrated_ego4d_test/bbox.json\"\n",
    "    # \"/ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma\"\n",
    "    # \"/eval_ego4d_scod_val_finetuned_45K_on_TREK150_all_frames_new\"\n",
    "    # \"/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    "    # \"/ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_wo_tool_no_stopwords\"\n",
    "    # \"/eval_ego4d_scod_val_finetuned_45K_on_TREK150_all_frames_new\"\n",
    "    # \"/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    "    # \"/ego4d_scod_all_frames_narrated_full_sentence\"\n",
    "    # \"/eval_ego4d_scod_val_finetuned_35K_on_TREK150_stepwise_all_frames\"\n",
    "    # \"/eval/model_0035000/inference/narrated_ego4d_test/bbox.json\"\n",
    "    # \"/ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma\"\n",
    "    # \"/eval_ego4d_scod_val_finetuned_45K_on_TREK150_all_frames_25percent_prepost\"\n",
    "    # \"/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    "    # \"/ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_defs\"\n",
    "    # \"/eval_ego4d_scod_val_finetuned_45K_on_TREK150_all_frames_25percent_prepost\"\n",
    "    # \"/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    "    # \"/ego4d_scod_all_frames_narrated_srl_arg1_only\"\n",
    "    # \"/eval_ego4d_scod_val_finetuned_55K_on_TREK150_stepwise_all_frames\"\n",
    "    # \"/eval/model_0055000/inference/narrated_ego4d_test/bbox.json\"\n",
    "    \"/ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma_defs_new_caps\"\n",
    "    \"/eval_ego4d_scod_val_finetuned_35K_on_TREK150_all_frames_25percent_prepost\"\n",
    "    \"/eval/model_0035000/inference/narrated_ego4d_test/bbox.json\"\n",
    ")\n",
    "\"\"\"\n",
    "coco_pred_file = (\n",
    "    \"/local1/bryanzhou008/jarvis/project_jarvis/baselines/ego4d-eccv2022-solutions\"\n",
    "    \"/scod/TREK-150-test-all_frame_complete.json\"\n",
    ")\n",
    "\n",
    "coco_gts = json.load(open(coco_gt_file))\n",
    "coco_gts_images = coco_gts[\"images\"]\n",
    "coco_gt_id_mapping = {}\n",
    "for coco_gt_image in coco_gts_images:\n",
    "    coco_gt_id_mapping[coco_gt_image[\"id\"]] = coco_gt_image[\"file_name\"]\n",
    "\n",
    "trek150_results = {}\n",
    "coco_preds = json.load(open(coco_pred_file))\n",
    "for coco_pred in tqdm(coco_preds, desc=\"COCO\"):\n",
    "    image_id = coco_pred[\"image_id\"]\n",
    "    file_name = coco_gt_id_mapping[image_id]\n",
    "    video_id = file_name.split(\"/\")[0]\n",
    "    image_name = file_name.split(\"/\")[-1]\n",
    "    frame_cnt = image_name.split(\"_\")[-1].split(\".\")[0]\n",
    "    frame_cnt_int = int(frame_cnt)\n",
    "    if video_id not in trek150_results:\n",
    "        trek150_results[video_id] = {}\n",
    "    frame_key = frame_cnt\n",
    "    if frame_key not in trek150_results[video_id]:\n",
    "        trek150_results[video_id][frame_key] = {\n",
    "            \"bboxes\": [],\n",
    "            \"scores\": [],\n",
    "            \"scored_bboxes\": [],\n",
    "        }\n",
    "    trek150_results[video_id][frame_key][\"bboxes\"].append(coco_pred[\"bbox\"])\n",
    "    trek150_results[video_id][frame_key][\"scores\"].append(coco_pred[\"score\"])\n",
    "    trek150_results[video_id][frame_key][\"scored_bboxes\"].append((coco_pred[\"score\"], coco_pred[\"bbox\"]))\n",
    "    \n",
    "for video_id in trek150_results:\n",
    "    for frame_key in trek150_results[video_id]:\n",
    "        trek150_results[video_id][frame_key][\"bboxes\"] = np.asarray(\n",
    "            trek150_results[video_id][frame_key][\"bboxes\"]\n",
    "        )\n",
    "        trek150_results[video_id][frame_key][\"scores\"] = np.asarray(\n",
    "            trek150_results[video_id][frame_key][\"scores\"]\n",
    "        )\n",
    "        scored_bboxes = sorted(\n",
    "            trek150_results[video_id][frame_key][\"scored_bboxes\"],\n",
    "            reverse=True\n",
    "        )\n",
    "        scores = [s for s, b in scored_bboxes]\n",
    "        bboxes = [b for s, b in scored_bboxes]\n",
    "        trek150_results[video_id][frame_key][\"bboxes\"] = np.asarray(bboxes)\n",
    "        trek150_results[video_id][frame_key][\"scores\"] = np.asarray(scores)\n",
    "        del trek150_results[video_id][frame_key][\"scored_bboxes\"]\n",
    "# pprint.pprint(trek150_results[\"P03-P03_02-612\"])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "json.dump(\n",
    "    trek150_results,\n",
    "    open(\n",
    "        (\n",
    "            \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "            \"/narrated_scod_finetuning_large_v2/eval_ego4d_scod_val_finetuned_45K_on_TREK150_all_frames\"\n",
    "            \"/eval/model_0045000/inference/narrated_ego4d_test/candidate_boxes.json\"\n",
    "        ),\n",
    "        \"w\"\n",
    "    ),\n",
    "    indent=4\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pickle.dump(\n",
    "    trek150_results,\n",
    "    open(\n",
    "        (\n",
    "            \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "            \"/narrated_scod_finetuning_large_v2/eval_ego4d_scod_val_finetuned_45K_on_TREK150_all_frames\"\n",
    "            \"/eval/model_0045000/inference/narrated_ego4d_test/candidate_boxes.pickle\"\n",
    "        ),\n",
    "        \"wb\"\n",
    "    )\n",
    ")\n",
    "pickle.dump(\n",
    "    trek150_results,\n",
    "    open(\n",
    "        (\n",
    "            \"/local1/telinwu/research/resources/TREK-150/baselines\"\n",
    "            \"/VideoIntern/eval_on_TREK150_all_frames/candidate_boxes.pickle\"\n",
    "        ),\n",
    "        \"wb\"\n",
    "    )\n",
    ")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "pickle.dump(\n",
    "    trek150_results,\n",
    "    open(\n",
    "        (\n",
    "            \"/local1/telinwu/research/resources/TREK-150/candidate_bboxes\"\n",
    "            # \"/GLIP/gpt_v1_symb_conds_mask/candidate_boxes.pickle\"\n",
    "            # \"/GLIP/gpt_v2_symb_conds_mask/candidate_boxes.pickle\"\n",
    "            # \"/GLIP/gpt_v2_no_symbs/candidate_boxes.pickle\"\n",
    "            # \"/GLIP/ground_full_sentence/candidate_boxes.pickle\"\n",
    "            # \"/GLIP/gpt_v2_symb_conds_mask_prepost/candidate_boxes.pickle\"\n",
    "            # \"/GLIP/gpt_v2_symb_defs/candidate_boxes.pickle\"\n",
    "            # \"/GLIP/srl_arg1_only/candidate_boxes.pickle\"\n",
    "            \"/GLIP/gpt_v2_symb_conds_mask_prepost_defs/candidate_boxes.pickle\"\n",
    "            \n",
    "        ),\n",
    "        \"wb\"\n",
    "    )\n",
    ")\n",
    "\"\"\"\n",
    "pickle.dump(\n",
    "    trek150_results,\n",
    "    open(\n",
    "        (\n",
    "            \"/local1/telinwu/research/resources/TREK-150/candidate_bboxes\"\n",
    "            \"/VideoIntern/candidate_boxes.pickle\"\n",
    "        ),\n",
    "        \"wb\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f7c86",
   "metadata": {},
   "source": [
    "#### Candidatr Bboxes to Run:\n",
    "**GPT**\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/gpt_v1_symb_conds_mask/candidate_boxes.pickle`\n",
    "  * From ego4d **ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma**\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/gpt_v2_symb_conds_mask/candidate_boxes.pickle`\n",
    "  * From ego4d **ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma**\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/gpt_v2_no_symbs/candidate_boxes.pickle`\n",
    "  * From ego4d **ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_wo_tool_no_stopwords**\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/gpt_v2_symb_conds_mask_prepost/candidate_boxes.pickle`\n",
    "  * From ego4d **ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma**\n",
    "  * Really added the pre/post conditional statements (prev ones forgot...)\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/gpt_v2_symb_defs/candidate_boxes.pickle`\n",
    "  * From ego4d **ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_defs**\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/gpt_v2_symb_conds_mask_prepost_defs/candidate_boxes.pickle`\n",
    "  * From ego4d **ego4d_scod_all_frames_narrated_gpt_v1_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma_defs_new_caps**\n",
    "* `path`\n",
    "  * File description?\n",
    "  \n",
    "**Baselines**\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/ground_full_sentence/candidate_boxes.pickle`\n",
    "  * From ego4d **ego4d_scod_all_frames_narrated_full_sentence**\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/gt_srl_arg1/candidate_boxes.pickle `\n",
    "  * From ego4d **narrated_scod_finetuning_large_v2** (Basically **gt-srl-arg1**)\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/VideoIntern/candidate_boxes.pickle`\n",
    "  * **VideoIntern-L** baseline\n",
    "* `/local1/telinwu/research/resources/TREK-150/candidate_bboxes/GLIP/srl_arg1_only/candidate_boxes.pickle`\n",
    "  * From ego4d **ego4d_scod_all_frames_narrated_srl_arg1_only**\n",
    "* `path`\n",
    "  * File description?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d76e5c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "class GPTSymbolic(object):\n",
    "    def __init__(self, ...):\n",
    "        self.gpt_instance = ...\n",
    "        # other params ...\n",
    "    \n",
    "    def _state_change(self, sent):\n",
    "        prompt = \"... {} ...\".format(sent)\n",
    "        response = self.gpt_instance(prompt)\n",
    "        return response\n",
    "    \n",
    "    def _spatial(self, sent):\n",
    "        prompt = \"... {} ...\".format(sent)\n",
    "        response = self.gpt_instance(prompt)\n",
    "        return response\n",
    "    \n",
    "    # More classes\n",
    "    \n",
    "    def get_gpt_response(self, sent, mode=None):\n",
    "        if mode == \"spatial\":\n",
    "            return self._spatial(sent)\n",
    "        # elif ...\n",
    "        \n",
    "    def pipeline(self, sent):\n",
    "        ooc, tool = self.get_gpt_response(sent, mode=\"obj_type\")\n",
    "        spatials = self.get_gpt_response(sent, mode=\"spatial\")\n",
    "        # ...\n",
    "        results = {\n",
    "            \"gpt_responses\": {\n",
    "                \"obj_type\": \"...\",\n",
    "                \"spatial\": \"...\"\n",
    "                # ...\n",
    "            }\n",
    "            \"parsed_responses\": {\n",
    "                \"spatials\": \"...\",\n",
    "                \"state_changes\": \"...\",\n",
    "            }\n",
    "        }\n",
    "        return results\n",
    "\"\"\"\n",
    "print(\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb27b1",
   "metadata": {},
   "source": [
    "# With Narrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e3aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ek_video_narrations(\n",
    "    video_id,\n",
    "    epic_kitchens_data,\n",
    "    verbose=False,\n",
    "):\n",
    "    frame_narration_list = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Video ID: {}\".format(video_id))\n",
    "    video = epic_kitchens_data[video_id]\n",
    "\n",
    "    event_id = 1\n",
    "    main_verbs = []\n",
    "    main_nouns = []\n",
    "    for event in video:\n",
    "        all_verbs, all_nouns = event[\"verb\"], event[\"all_nouns\"]\n",
    "        main_verbs += [all_verbs]\n",
    "        main_nouns += all_nouns\n",
    "    main_verbs = sorted(list(set(main_verbs)))\n",
    "    main_nouns = sorted(list(set(main_nouns)))\n",
    "    if verbose:\n",
    "        print(\"Main Verbs: {}\".format(main_verbs))\n",
    "        print(\"Main Nouns: {}\".format(main_nouns))\n",
    "    prev_stop_time = None\n",
    "    for event in video:\n",
    "        start_timestamp, stop_timestamp = event[\"start_timestamp\"], event[\"stop_timestamp\"]\n",
    "        start_frame, stop_frame = int(event[\"start_frame\"]), int(event[\"stop_frame\"])\n",
    "        narration = event[\"narration\"]\n",
    "        t = datetime.strptime(start_timestamp, \"%H:%M:%S.%f\")\n",
    "        delta = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second, microseconds=t.microsecond)\n",
    "        curr_start_time = delta.total_seconds()\n",
    "        t = datetime.strptime(stop_timestamp, \"%H:%M:%S.%f\")\n",
    "        delta = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second, microseconds=t.microsecond)\n",
    "        curr_stop_time = delta.total_seconds()\n",
    "        if verbose:\n",
    "            if prev_stop_time is not None and curr_start_time < prev_stop_time:\n",
    "                print(\"({:04d}) [{}-{}] {} (↑)\".format(event_id, start_timestamp, stop_timestamp, narration))\n",
    "            else:\n",
    "                print(\"({:04d}) [{}-{}] {} \".format(event_id, start_timestamp, stop_timestamp, narration))\n",
    "        event_id += 1\n",
    "        prev_stop_time = curr_stop_time\n",
    "        frame_narration_list.append((start_frame, stop_frame, (start_frame+stop_frame)//2, narration))\n",
    "    \n",
    "    return frame_narration_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a758ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "epic_kitchens_root = \"/local1/telinwu/research/resources/EPIC-KITCHENS-100/\"\n",
    "epic_kitchens_train_file = \"EPIC_100_train.csv\"\n",
    "epic_kitchens_train_file = os.path.join(epic_kitchens_root, \"epic-kitchens-100-annotations\", epic_kitchens_train_file)\n",
    "epic_kitchens_csv = csv.DictReader(open(epic_kitchens_train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e10bf653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['Nothing', 'Nothing'],\n",
      " 1: ['pan',\n",
      "     'pan',\n",
      "     'sauce',\n",
      "     'frying',\n",
      "     'cake',\n",
      "     'saucepan',\n",
      "     'empty',\n",
      "     'small',\n",
      "     'wok',\n",
      "     'scour',\n",
      "     'content'],\n",
      " 2: ['pan:dust', 'dust', 'dustpan'],\n",
      " 3: ['tap', 'tap', 'water', 'nozzle', 'coffee'],\n",
      " 4: ['plate',\n",
      "     'plate',\n",
      "     'pasta',\n",
      "     'saucer',\n",
      "     'dish',\n",
      "     'salad',\n",
      "     'lasagna',\n",
      "     'plate',\n",
      "     'flatware',\n",
      "     'pate'],\n",
      " 5: ['knife',\n",
      "     'knife',\n",
      "     'mincing',\n",
      "     'using',\n",
      "     'blade',\n",
      "     'chopper',\n",
      "     'mezzaluna',\n",
      "     'moon',\n",
      "     'mezzaluna'],\n",
      " 6: ['bowl',\n",
      "     'bowl',\n",
      "     'salad',\n",
      "     'glass',\n",
      "     'sugar',\n",
      "     'empty',\n",
      "     'cooker',\n",
      "     'washing',\n",
      "     'egg',\n",
      "     'processor'],\n",
      " 7: ['spoon',\n",
      "     'spoon',\n",
      "     'wooden',\n",
      "     'using',\n",
      "     'teaspoon',\n",
      "     'spoon',\n",
      "     'spade',\n",
      "     'food',\n",
      "     'coffee',\n",
      "     'tea',\n",
      "     'measure',\n",
      "     'coffee',\n",
      "     'scoop',\n",
      "     'stirrer',\n",
      "     'tablespoon'],\n",
      " 8: ['cupboard',\n",
      "     'cupboard',\n",
      "     'cabinet',\n",
      "     'locker',\n",
      "     'flap',\n",
      "     'door',\n",
      "     'cabinet',\n",
      "     'cupboard',\n",
      "     'closet'],\n",
      " 9: ['drawer', 'drawer', 'dishwasher', 'freezer', 'refrigerator', 'draw'],\n",
      " 10: ['fridge', 'fridge', 'refrigerator', 'refrigerator', 'fridge'],\n",
      " 11: ['lid',\n",
      "      'lid',\n",
      "      'pot',\n",
      "      'tin',\n",
      "      'saucepan',\n",
      "      'tupperware',\n",
      "      'box',\n",
      "      'pan',\n",
      "      'bottle',\n",
      "      'teapot',\n",
      "      'kettle',\n",
      "      'yoghurt',\n",
      "      'chopper',\n",
      "      'seal'],\n",
      " 12: ['hand', 'hand', 'using', 'my'],\n",
      " 13: ['onion', 'onion', 'cutting', 'onion', 'onion'],\n",
      " 14: ['onion:spring', 'spring'],\n",
      " 15: ['pot',\n",
      "      'pot',\n",
      "      'coffee',\n",
      "      'small',\n",
      "      'white',\n",
      "      'right',\n",
      "      'left',\n",
      "      'teapot',\n",
      "      'second',\n",
      "      'teapot',\n",
      "      'teapot',\n",
      "      'pressure',\n",
      "      'pasta',\n",
      "      'sauce',\n",
      "      'third',\n",
      "      'first'],\n",
      " 16: ['glass', 'glass', 'wine', 'empty'],\n",
      " 17: ['water', 'water', 'tap', 'empty', 'excess', 'hot', 'more', 'water'],\n",
      " 18: ['fork', 'fork', 'soap'],\n",
      " 19: ['board:chopping',\n",
      "      'chopping',\n",
      "      'cutting',\n",
      "      'board',\n",
      "      'serving',\n",
      "      'chopping',\n",
      "      'cut',\n",
      "      'block'],\n",
      " 20: ['bag',\n",
      "      'bag',\n",
      "      'plastic',\n",
      "      'pasta',\n",
      "      'mozzarella',\n",
      "      'cereal',\n",
      "      'grape',\n",
      "      'flour',\n",
      "      'cheese',\n",
      "      'nut',\n",
      "      'rice',\n",
      "      'oregano',\n",
      "      'salad',\n",
      "      'bin',\n",
      "      'coffee',\n",
      "      'spaghetti',\n",
      "      'food',\n",
      "      'trash',\n",
      "      'onion',\n",
      "      'carrot',\n",
      "      'bread',\n",
      "      'grapes',\n",
      "      'sandwich',\n",
      "      'kitchen'],\n",
      " 21: ['sponge', 'sponge', 'scrubber'],\n",
      " 22: ['spatula', 'spatula', 'wooden', 'spate'],\n",
      " 23: ['cup', 'cup', 'coffee', 'measuring', 'small', 'mug', 'rinse', 'clean'],\n",
      " 24: ['oil', 'oil', 'olive', 'chilli', 'sesame'],\n",
      " 25: ['bin',\n",
      "      'bin',\n",
      "      'trash',\n",
      "      'dust',\n",
      "      'food',\n",
      "      'dustbin',\n",
      "      'rubbish',\n",
      "      'garbage',\n",
      "      'recycling',\n",
      "      'waste',\n",
      "      'wastebasket'],\n",
      " 26: ['meat', 'meat', 'minced', 'meat', 'meat', 'mix', 'mincemeat', 'mince'],\n",
      " 27: ['potato', 'potato', 'baby'],\n",
      " 28: ['bottle', 'bottle', 'oil', 'milk', 'water', 'sauce', 'pesto', 'vinegar'],\n",
      " 29: ['container',\n",
      "      'container',\n",
      "      'food',\n",
      "      'milk',\n",
      "      'sauce',\n",
      "      'rice',\n",
      "      'tofu',\n",
      "      'sugar',\n",
      "      'salt',\n",
      "      'tomato',\n",
      "      'pasta',\n",
      "      'cake',\n",
      "      'bread',\n",
      "      'bucket'],\n",
      " 30: ['tomato', 'tomato', 'dried', 'cherry', 'chopped', 'sun'],\n",
      " 31: ['salt', 'salt', 'seasoning'],\n",
      " 32: ['cloth',\n",
      "      'cloth',\n",
      "      'table',\n",
      "      'rag',\n",
      "      'dish',\n",
      "      'cleaning',\n",
      "      'washing',\n",
      "      'dishrag'],\n",
      " 33: ['sink', 'sink', 'kitchen', 'water'],\n",
      " 34: ['door:kitchen', 'kitchen'],\n",
      " 35: ['pasta', 'pasta', 'spaghetti', 'pasta', 'lasagne'],\n",
      " 36: ['dish:soap', 'soap'],\n",
      " 37: ['food', 'food', 'scoop', 'food', 'food', 'grocery'],\n",
      " 38: ['kettle', 'kettle'],\n",
      " 39: ['box',\n",
      "      'box',\n",
      "      'lunch',\n",
      "      'cereal',\n",
      "      'tea',\n",
      "      'salt',\n",
      "      'tupperware',\n",
      "      'lunchbox',\n",
      "      'case',\n",
      "      'mushroom',\n",
      "      'coffee',\n",
      "      'cheese',\n",
      "      'milk',\n",
      "      'rice',\n",
      "      'carrot',\n",
      "      'fruit',\n",
      "      'plastic',\n",
      "      'tub',\n",
      "      'plastic',\n",
      "      'eggs',\n",
      "      'fajita'],\n",
      " 40: ['carrot', 'carrot', 'tail'],\n",
      " 41: ['sauce',\n",
      "      'sauce',\n",
      "      'soy',\n",
      "      'fish',\n",
      "      'pesto',\n",
      "      'tomato',\n",
      "      'salsa',\n",
      "      'tabasco',\n",
      "      'soya',\n",
      "      'soy',\n",
      "      'passata',\n",
      "      'mirin'],\n",
      " 42: ['colander', 'colander', 'pasta'],\n",
      " 43: ['milk', 'milk', 'soy', 'coconut', 'soya'],\n",
      " 44: ['rice', 'rice', 'scoop'],\n",
      " 45: ['garlic', 'garlic', 'chop', 'peel', 'garlic', 'clove', 'garlic', 'bulb'],\n",
      " 46: ['pepper', 'pepper', 'bell'],\n",
      " 47: ['hob', 'hob', 'stove', 'gas', 'burners', 'hop', 'hot', 'burner'],\n",
      " 48: ['dough', 'dough'],\n",
      " 49: ['dishwasher', 'dishwasher', 'dishwater'],\n",
      " 50: ['egg', 'egg', 'egg'],\n",
      " 51: ['cheese',\n",
      "      'cheese',\n",
      "      'cheese',\n",
      "      'cheese',\n",
      "      'mozzarella',\n",
      "      'paneer',\n",
      "      'mozzarella',\n",
      "      'parmesan'],\n",
      " 52: ['bread',\n",
      "      'bread',\n",
      "      'white',\n",
      "      'toast',\n",
      "      'loaf',\n",
      "      'rusk',\n",
      "      'toast',\n",
      "      'hamburger',\n",
      "      'bread',\n",
      "      'ciabatta',\n",
      "      'sandwich'],\n",
      " 53: ['table', 'table', 'round'],\n",
      " 54: ['salad', 'salad', 'cucumber'],\n",
      " 55: ['microwave', 'microwave', 'microwave'],\n",
      " 56: ['oven', 'oven', 'adjust', 'cooker', 'oven'],\n",
      " 57: ['cooker:slow', 'slow', 'rice'],\n",
      " 58: ['coffee',\n",
      "      'coffee',\n",
      "      'scoop',\n",
      "      'coffee',\n",
      "      'coffee',\n",
      "      'coffee',\n",
      "      'coffee',\n",
      "      'coffee',\n",
      "      'grounds',\n",
      "      'ground'],\n",
      " 59: ['filter',\n",
      "      'filter',\n",
      "      'water',\n",
      "      'coffee',\n",
      "      'empty',\n",
      "      'sink',\n",
      "      'filter',\n",
      "      'sink',\n",
      "      'stud'],\n",
      " 60: ['jar', 'jar', 'sugar', 'coffee', 'filter', 'salt', 'honey'],\n",
      " 61: ['rack:drying', 'drying', 'rack', 'dish', 'drainer'],\n",
      " 62: ['chicken', 'chicken', 'chicken', 'chicken', 'chicken', 'breast'],\n",
      " 63: ['tray', 'tray', 'baking', 'baking', 'pizza', 'baking', 'tin'],\n",
      " 64: ['mixture', 'mixture', 'mix'],\n",
      " 65: ['towel', 'towel', 'tea'],\n",
      " 66: ['towel:kitchen', 'kitchen', 'paper', 'kitchen'],\n",
      " 67: ['peach', 'peach', 'peach'],\n",
      " 68: ['skin',\n",
      "      'skin',\n",
      "      'onion',\n",
      "      'potato',\n",
      "      'peel',\n",
      "      'onion',\n",
      "      'peeling',\n",
      "      'onion',\n",
      "      'carrot',\n",
      "      'rind',\n",
      "      'squash',\n",
      "      'carrot',\n",
      "      'banana'],\n",
      " 69: ['courgette', 'courgette', 'courgette'],\n",
      " 70: ['liquid:washing',\n",
      "      'washing',\n",
      "      'cleaning',\n",
      "      'detergent',\n",
      "      'degreaser',\n",
      "      'cleanser',\n",
      "      'spray',\n",
      "      'cleaner',\n",
      "      'dish',\n",
      "      'product'],\n",
      " 71: ['liquid', 'liquid'],\n",
      " 72: ['leaf', 'leaf', 'lettuce', 'salad', 'spinach', 'bay'],\n",
      " 73: ['lettuce', 'lettuce', 'rocket'],\n",
      " 74: ['leaf:mint', 'mint', 'curry'],\n",
      " 75: ['cutlery', 'cutlery', 'fork', 'silverware', 'tableware'],\n",
      " 76: ['scissors', 'scissors', 'scissor'],\n",
      " 77: ['package',\n",
      "      'package',\n",
      "      'cheese',\n",
      "      'bread',\n",
      "      'cooky',\n",
      "      'popcorn',\n",
      "      'mozzarella',\n",
      "      'parsley',\n",
      "      'salad',\n",
      "      'pasta',\n",
      "      'packaging',\n",
      "      'salad',\n",
      "      'bread',\n",
      "      'packet',\n",
      "      'cheese',\n",
      "      'pack',\n",
      "      'tortilla',\n",
      "      'tea',\n",
      "      'egg',\n",
      "      'wrapper',\n",
      "      'plastic',\n",
      "      'sausage',\n",
      "      'cookies',\n",
      "      'soup',\n",
      "      'bacon',\n",
      "      'oat',\n",
      "      'carton',\n",
      "      'beef',\n",
      "      'tea',\n",
      "      'meat',\n",
      "      'sachet',\n",
      "      'cookies',\n",
      "      'cheese',\n",
      "      'milk',\n",
      "      'flavour',\n",
      "      'sausage',\n",
      "      'cream',\n",
      "      'salt',\n",
      "      'salad',\n",
      "      'meat',\n",
      "      'pasta',\n",
      "      'fajita',\n",
      "      'wrap',\n",
      "      'spice',\n",
      "      'egg',\n",
      "      'cardboard',\n",
      "      'wrapping'],\n",
      " 78: ['top',\n",
      "      'top',\n",
      "      'counter',\n",
      "      'stove',\n",
      "      'surface',\n",
      "      'hob',\n",
      "      'wipe',\n",
      "      'counter',\n",
      "      'kitchen',\n",
      "      'side',\n",
      "      'kitchen',\n",
      "      'tile'],\n",
      " 79: ['spice', 'spice'],\n",
      " 80: ['tortilla', 'tortilla'],\n",
      " 81: ['paper', 'paper', 'baking', 'cooking', 'letter'],\n",
      " 82: ['machine:washing', 'washing', 'machine', 'washer', 'washer', 'machine'],\n",
      " 83: ['olive', 'olive'],\n",
      " 84: ['sausage', 'sausage', 'chorizo'],\n",
      " 85: ['glove:oven', 'oven', 'glove', 'mitt', 'oven', 'mitten'],\n",
      " 86: ['peeler:potato', 'potato', 'peeler', 'carrot', 'skinner', 'carrot'],\n",
      " 87: ['can', 'can', 'tin', 'tomato'],\n",
      " 88: ['mat', 'mat', 'place', 'eating', 'placemat'],\n",
      " 89: ['mat:sushi', 'sushi'],\n",
      " 90: ['vegetable', 'vegetable'],\n",
      " 91: ['wrap:plastic', 'plastic', 'transparent', 'cling', 'film'],\n",
      " 92: ['wrap', 'wrap'],\n",
      " 93: ['flour', 'flour', 'flour', 'flour'],\n",
      " 94: ['cucumber', 'cucumber'],\n",
      " 95: ['curry', 'curry', 'fish', 'bean', 'saag', 'masala'],\n",
      " 96: ['cereal', 'cereal', 'shreddies', 'granola', 'cereal'],\n",
      " 97: ['napkin', 'napkin'],\n",
      " 98: ['soap', 'soap'],\n",
      " 99: ['squash', 'squash'],\n",
      " 100: ['fish', 'fish', 'fish', 'fish', 'fish', 'salmon'],\n",
      " 101: ['chilli', 'chilli', 'chop', 'red', 'slice', 'chilli'],\n",
      " 102: ['cover', 'cover', 'plastic', 'plate', 'dish'],\n",
      " 103: ['sugar', 'sugar'],\n",
      " 104: ['aubergine', 'aubergine'],\n",
      " 105: ['jug', 'jug', 'measuring', 'pitcher', 'carafe', 'rinse'],\n",
      " 106: ['heat', 'heat', 'temperature', 'gas', 'cooker', 'cooker', 'temp'],\n",
      " 107: ['leek', 'leek', 'leek'],\n",
      " 108: ['rubbish', 'rubbish', 'trash', 'garbage', 'waste'],\n",
      " 109: ['ladle', 'ladle'],\n",
      " 110: ['mushroom', 'mushroom'],\n",
      " 111: ['stock', 'stock', 'stock'],\n",
      " 112: ['freezer', 'freezer'],\n",
      " 113: ['light', 'light'],\n",
      " 114: ['pizza', 'pizza', 'pizza'],\n",
      " 115: ['ball', 'ball'],\n",
      " 116: ['yoghurt', 'yoghurt'],\n",
      " 117: ['chopstick', 'chopstick', 'chop'],\n",
      " 118: ['grape', 'grape'],\n",
      " 119: ['ginger', 'ginger', 'ginger', 'galangal', 'galangal'],\n",
      " 120: ['banana', 'banana'],\n",
      " 121: ['oregano', 'oregano'],\n",
      " 122: ['tuna', 'tuna', 'tuna'],\n",
      " 123: ['kitchen', 'kitchen'],\n",
      " 124: ['salmon', 'salmon'],\n",
      " 125: ['basket', 'basket', 'hamper'],\n",
      " 126: ['maker:coffee',\n",
      "       'coffee',\n",
      "       'v60',\n",
      "       'cafetiere',\n",
      "       'rinse',\n",
      "       'maker',\n",
      "       'coffee',\n",
      "       'moka',\n",
      "       'mocha',\n",
      "       'moka'],\n",
      " 127: ['roll', 'roll'],\n",
      " 128: ['brush', 'brush', 'brusher', 'pastry', 'broom', 'wool', 'steel'],\n",
      " 129: ['lemon', 'lemon', 'lemon'],\n",
      " 130: ['clothes', 'clothes', 'laundry', 'washing', 'washing'],\n",
      " 131: ['grater', 'grater', 'cheese'],\n",
      " 132: ['strainer', 'strainer', 'mesh', 'sieve'],\n",
      " 133: ['bacon', 'bacon'],\n",
      " 134: ['avocado', 'avocado'],\n",
      " 135: ['blueberry', 'blueberry'],\n",
      " 136: ['pesto', 'pesto'],\n",
      " 137: ['utensil', 'utensil', 'skimmer'],\n",
      " 138: ['bean:green', 'green', 'bean'],\n",
      " 139: ['floor', 'floor'],\n",
      " 140: ['lime', 'lime', 'lime'],\n",
      " 141: ['foil', 'foil', 'kitchen', 'aluminium'],\n",
      " 142: ['grill', 'grill'],\n",
      " 143: ['ingredient', 'ingredient', 'pan'],\n",
      " 144: ['scale', 'scale', 'weighing', 'scales', 'balance'],\n",
      " 145: ['paste:garlic', 'garlic', 'miso', 'paste', 'shrimp', 'pepper', 'nut'],\n",
      " 146: ['processor:food', 'food', 'processor', 'processor'],\n",
      " 147: ['nut:pine', 'pine', 'nut', 'peanut', 'pine'],\n",
      " 148: ['butter', 'butter'],\n",
      " 149: ['butter:peanut', 'peanut'],\n",
      " 150: ['shelf', 'shelf', 'utensil'],\n",
      " 151: ['timer', 'timer', 'oven'],\n",
      " 152: ['rinse', 'rinse'],\n",
      " 153: ['tablecloth', 'tablecloth'],\n",
      " 154: ['switch', 'switch'],\n",
      " 155: ['powder:coconut', 'coconut', 'curry', 'baking', 'powder', 'garlic'],\n",
      " 156: ['powder:washing', 'washing', 'persil'],\n",
      " 157: ['capsule', 'capsule', 'empty'],\n",
      " 158: ['oat', 'oat'],\n",
      " 159: ['tofu', 'tofu', 'bean', 'curd'],\n",
      " 160: ['lighter', 'lighter'],\n",
      " 161: ['corn', 'corn', 'sweet', 'corn', 'cob', 'corncob', 'sweetcorn'],\n",
      " 162: ['vinegar', 'vinegar', 'balsamic', 'wine', 'rice', 'reduction'],\n",
      " 163: ['grinder', 'grinder', 'coffee'],\n",
      " 164: ['cap', 'cap', 'sink'],\n",
      " 165: ['support', 'support', 'pan', 'trivet'],\n",
      " 166: ['cream', 'cream', 'creme', 'fraiche'],\n",
      " 167: ['content', 'content', 'pan'],\n",
      " 168: ['tongs', 'tongs', 'tong'],\n",
      " 169: ['pie', 'pie', 'pastry'],\n",
      " 170: ['fan:extractor', 'extractor', 'fan', 'ventilator', 'hood'],\n",
      " 171: ['raisin', 'raisin'],\n",
      " 172: ['toaster', 'toaster'],\n",
      " 173: ['broccoli', 'broccoli'],\n",
      " 174: ['pin:rolling', 'rolling', 'pin'],\n",
      " 175: ['plug', 'plug', 'socket'],\n",
      " 176: ['button', 'button'],\n",
      " 177: ['tea', 'tea', 'tea', 'teabag'],\n",
      " 178: ['parsley', 'parsley'],\n",
      " 179: ['flame', 'flame'],\n",
      " 180: ['herb', 'herb'],\n",
      " 181: ['base', 'base', 'pizza'],\n",
      " 182: ['holder:filter', 'filter', 'pot', 'holder', 'jug'],\n",
      " 183: ['thyme', 'thyme'],\n",
      " 184: ['honey', 'honey'],\n",
      " 185: ['celery', 'celery'],\n",
      " 186: ['kiwi', 'kiwi'],\n",
      " 187: ['tissue', 'tissue'],\n",
      " 188: ['time', 'time', 'cooking'],\n",
      " 189: ['clip', 'clip', 'bag'],\n",
      " 190: ['noodle', 'noodle'],\n",
      " 191: ['yeast', 'yeast'],\n",
      " 192: ['hummus', 'hummus', 'humus'],\n",
      " 193: ['coconut', 'coconut'],\n",
      " 194: ['cabbage', 'cabbage'],\n",
      " 195: ['spinach', 'spinach'],\n",
      " 196: ['nutella', 'nutella'],\n",
      " 197: ['fruit', 'fruit'],\n",
      " 198: ['dressing:salad', 'salad', 'dressing'],\n",
      " 199: ['omelette', 'omelette', 'tamagoyaki', 'frittata'],\n",
      " 200: ['kale', 'kale'],\n",
      " 201: ['paella', 'paella'],\n",
      " 202: ['chip', 'chip'],\n",
      " 203: ['opener:bottle', 'bottle', 'can', 'corkscrew', 'opener'],\n",
      " 204: ['shirt', 'shirt', 't', 'tee'],\n",
      " 205: ['chair', 'chair'],\n",
      " 206: ['sandwich', 'sandwich'],\n",
      " 207: ['burger:tuna', 'tuna', 'patty', 'tuna', 'burger', 'hamburger'],\n",
      " 208: ['pancake', 'pancake'],\n",
      " 209: ['leftover', 'leftover', 'leftover'],\n",
      " 210: ['risotto', 'risotto'],\n",
      " 211: ['pestle', 'pestle'],\n",
      " 212: ['sock', 'sock'],\n",
      " 213: ['pea', 'pea'],\n",
      " 214: ['apron', 'apron'],\n",
      " 215: ['juice', 'juice', 'lemon'],\n",
      " 216: ['wine', 'wine'],\n",
      " 217: ['dust', 'dust'],\n",
      " 218: ['desk', 'desk'],\n",
      " 219: ['mesh', 'mesh'],\n",
      " 220: ['oatmeal', 'oatmeal'],\n",
      " 221: ['artichoke', 'artichoke'],\n",
      " 222: ['remover:spot', 'spot'],\n",
      " 223: ['coriander', 'coriander', 'cilantro'],\n",
      " 224: ['mocha', 'mocha'],\n",
      " 225: ['quorn', 'quorn'],\n",
      " 226: ['soup', 'soup'],\n",
      " 227: ['turmeric', 'turmeric'],\n",
      " 228: ['knob', 'knob', 'dial'],\n",
      " 229: ['seed', 'seed', 'pit', 'squash'],\n",
      " 230: ['boxer', 'boxer', 'boxer'],\n",
      " 231: ['paprika', 'paprika'],\n",
      " 232: ['juicer:lime', 'lime'],\n",
      " 233: ['guard:hand', 'hand', 'guard'],\n",
      " 234: ['apple', 'apple'],\n",
      " 235: ['tahini', 'tahini'],\n",
      " 236: ['finger', 'finger'],\n",
      " 237: ['salami', 'salami', 'ham', 'prosciutto'],\n",
      " 238: ['mayonnaise', 'mayonnaise'],\n",
      " 239: ['biscuit', 'biscuit', 'cookie', 'cooky', 'cracker'],\n",
      " 240: ['pear', 'pear'],\n",
      " 241: ['mortar', 'mortar', 'mortar'],\n",
      " 242: ['berry', 'berry'],\n",
      " 243: ['beef', 'beef', 'steak'],\n",
      " 244: ['squeezer:lime', 'lime'],\n",
      " 245: ['tail', 'tail'],\n",
      " 246: ['stick:crab', 'crab'],\n",
      " 247: ['supplement', 'supplement'],\n",
      " 248: ['phone', 'phone', 'mobile'],\n",
      " 249: ['shell:egg', 'egg', 'eggshell', 'shell'],\n",
      " 250: ['pith', 'pith'],\n",
      " 251: ['ring:onion', 'onion', 'ring'],\n",
      " 252: ['cherry', 'cherry'],\n",
      " 253: ['cake', 'cake'],\n",
      " 254: ['sprout', 'sprout'],\n",
      " 255: ['almond', 'almond'],\n",
      " 256: ['mint', 'mint'],\n",
      " 257: ['flake:chilli', 'chilli', 'flake'],\n",
      " 258: ['cutter:pizza', 'pizza', 'cutter'],\n",
      " 259: ['nesquik', 'nesquik'],\n",
      " 260: ['blender', 'blender', 'mixer'],\n",
      " 261: ['scrap', 'scrap'],\n",
      " 262: ['backpack', 'backpack'],\n",
      " 263: ['melon', 'melon'],\n",
      " 264: ['breadcrumb', 'breadcrumb', 'bread'],\n",
      " 265: ['sticker', 'sticker'],\n",
      " 266: ['shrimp', 'shrimp'],\n",
      " 267: ['smoothie', 'smoothie'],\n",
      " 268: ['grass:lemon', 'lemon'],\n",
      " 269: ['ketchup', 'ketchup'],\n",
      " 270: ['slicer', 'slicer', 'cutting'],\n",
      " 271: ['stand', 'stand'],\n",
      " 272: ['dumpling', 'dumpling'],\n",
      " 273: ['watch', 'watch'],\n",
      " 274: ['beer', 'beer'],\n",
      " 275: ['power', 'power'],\n",
      " 276: ['heater', 'heater'],\n",
      " 277: ['basil', 'basil', 'basil'],\n",
      " 278: ['cinnamon', 'cinnamon'],\n",
      " 279: ['crisp', 'crisp'],\n",
      " 280: ['asparagus', 'asparagus'],\n",
      " 281: ['drink', 'drink', 'soda'],\n",
      " 282: ['fishcakes', 'fishcakes', 'fish', 'fishcake'],\n",
      " 283: ['mustard', 'mustard'],\n",
      " 284: ['caper', 'caper'],\n",
      " 285: ['whetstone', 'whetstone', 'knife', 'sharpener', 'sharpening', 'stone'],\n",
      " 286: ['candle', 'candle'],\n",
      " 287: ['control:remote', 'remote', 'control', 'remote'],\n",
      " 288: ['instruction', 'instruction'],\n",
      " 289: ['cork', 'cork', 'stopper'],\n",
      " 290: ['tab', 'tab'],\n",
      " 291: ['masher', 'masher'],\n",
      " 292: ['part', 'part'],\n",
      " 293: ['muffin', 'muffin'],\n",
      " 294: ['shaker:pepper', 'pepper'],\n",
      " 295: ['garni:bouquet', 'bouquet'],\n",
      " 296: ['popcorn', 'popcorn'],\n",
      " 297: ['envelope', 'envelope'],\n",
      " 298: ['chocolate', 'chocolate'],\n",
      " 299: ['spot', 'spot'],\n",
      " 300: ['window', 'window'],\n",
      " 301: ['syrup', 'syrup', 'maple'],\n",
      " 302: ['bar:cereal', 'cereal', 'bar'],\n",
      " 303: ['croissant', 'croissant'],\n",
      " 304: ['coke', 'coke'],\n",
      " 305: ['stereo', 'stereo'],\n",
      " 306: ['alarm', 'alarm'],\n",
      " 307: ['recipe', 'recipe'],\n",
      " 308: ['handle', 'handle'],\n",
      " 309: ['sleeve', 'sleeve'],\n",
      " 310: ['cumin', 'cumin', 'jeera'],\n",
      " 311: ['wire', 'wire'],\n",
      " 312: ['label', 'label'],\n",
      " 313: ['fire', 'fire'],\n",
      " 314: ['presser', 'presser', 'squeezer', 'press', 'garlic', 'juicer'],\n",
      " 315: ['air', 'air'],\n",
      " 316: ['mouse', 'mouse'],\n",
      " 317: ['boiler', 'boiler'],\n",
      " 318: ['rest', 'rest', 'spoon', 'spoon'],\n",
      " 319: ['tablet', 'tablet'],\n",
      " 320: ['poster', 'poster'],\n",
      " 321: ['trousers', 'trousers'],\n",
      " 322: ['form', 'form'],\n",
      " 323: ['rubber', 'rubber', 'rubber'],\n",
      " 324: ['rug', 'rug'],\n",
      " 325: ['sheets', 'sheets', 'sheet'],\n",
      " 326: ['pepper:cayenne', 'cayenne'],\n",
      " 327: ['waffle', 'waffle'],\n",
      " 328: ['pineapple', 'pineapple'],\n",
      " 329: ['turkey', 'turkey'],\n",
      " 330: ['alcohol', 'alcohol'],\n",
      " 331: ['rosemary', 'rosemary'],\n",
      " 332: ['lead', 'lead'],\n",
      " 333: ['book', 'book', 'national'],\n",
      " 334: ['rim', 'rim'],\n",
      " 335: ['gravy', 'gravy'],\n",
      " 336: ['straw', 'straw'],\n",
      " 337: ['hat', 'hat'],\n",
      " 338: ['cd', 'cd'],\n",
      " 339: ['slipper', 'slipper'],\n",
      " 340: ['casserole', 'casserole'],\n",
      " 341: ['ladder', 'ladder'],\n",
      " 342: ['jambalaya', 'jambalaya'],\n",
      " 343: ['wall', 'wall'],\n",
      " 344: ['tube', 'tube'],\n",
      " 345: ['lamp', 'lamp'],\n",
      " 346: ['tarragon', 'tarragon'],\n",
      " 347: ['heart', 'heart'],\n",
      " 348: ['funnel', 'funnel'],\n",
      " 349: ['whisk', 'whisk'],\n",
      " 350: ['driver:screw', 'screw'],\n",
      " 351: ['trouser', 'trouser']}\n"
     ]
    }
   ],
   "source": [
    "action_class_mappings = {\n",
    "    \"verb\": {},\n",
    "    \"noun\": {},\n",
    "}\n",
    "\n",
    "class_mapping_csv =  {\n",
    "    \"verb\": \"/local1/bryanzhou008/jarvis/epic_kitchen/epic-kitchens-55-annotations/EPIC_verb_classes.csv\",\n",
    "    \"noun\": \"/local1/bryanzhou008/jarvis/epic_kitchen/epic-kitchens-55-annotations/EPIC_noun_classes.csv\",\n",
    "}\n",
    "verb_class_mapping_csv = \"/local1/bryanzhou008/jarvis/epic_kitchen/epic-kitchens-55-annotations/EPIC_verb_classes.csv\"\n",
    "\n",
    "for class_type in class_mapping_csv:\n",
    "    csv_reader = csv.DictReader(open(class_mapping_csv[class_type], \"r\"))\n",
    "    for row in csv_reader:\n",
    "        class_id = row[\"{}_id\".format(class_type)]\n",
    "        class_key = row[\"class_key\"]\n",
    "        allowed = ast.literal_eval(row[\"{}s\".format(class_type)])\n",
    "        allowed = [x.split(\":\")[-1] for x in allowed]\n",
    "        action_class_mappings[class_type][int(class_id)] = [class_key] + allowed\n",
    "pass\n",
    "\n",
    "pprint.pprint(action_class_mappings[\"noun\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1307e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "epic_kitchens_data = {}\n",
    "\n",
    "for row in epic_kitchens_csv:\n",
    "    video_id = row[\"video_id\"]\n",
    "    if video_id not in epic_kitchens_data:\n",
    "        epic_kitchens_data[video_id] = []\n",
    "    \n",
    "    curr_timestamp = {}\n",
    "    for key in row:\n",
    "        if key in [\"video_id\", \"participant_id\", \"narration_id\", \"narration_timestamp\"]:\n",
    "            continue\n",
    "        if key in [\"all_nouns\", \"all_noun_classes\"]:\n",
    "            row[key] = literal_eval(row[key])\n",
    "        curr_timestamp[key] = row[key]\n",
    "    epic_kitchens_data[video_id].append(curr_timestamp)\n",
    "    \n",
    "for video_id in epic_kitchens_data:\n",
    "    epic_kitchens_data[video_id] = sorted(\n",
    "        epic_kitchens_data[video_id],\n",
    "        key=lambda x: int(x[\"start_frame\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb18c75d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(194, 486, 340, 'put bags'), (390, 454, 422, 'take squash'), (454, 515, 484, 'put squash'), (537, 588, 562, 'take salmon'), (583, 635, 609, 'put salmon')]\n"
     ]
    }
   ],
   "source": [
    "video_id = \"P03-P03_02-612\"\n",
    "video_id = \"P03-P03_04-57\"\n",
    "ek_video_id = video_id.split(\"-\")[1]\n",
    "\n",
    "frame_narration_list = print_ek_video_narrations(\n",
    "    ek_video_id,\n",
    "    epic_kitchens_data,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(frame_narration_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0266ffd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:   3%|██▊                                                                                | 5/150 [00:00<00:05, 28.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn on tap\n",
      "['pan', 'pan', 'sauce', 'frying', 'cake', 'saucepan', 'empty', 'small', 'wok', 'scour', 'content']\n",
      "[11, 3, 1]\n",
      "22440 22690\n",
      "[(22391, 22597, 'turn on tap'),\n",
      " (22663, 22707, 'turn off tap'),\n",
      " (22307, 22358, 'push bin back'),\n",
      " (22100, 22301, 'put lid on bin'),\n",
      " (21801, 22121, 'open bag')]\n",
      "P03-P03_02-56\n",
      "dry pan\n",
      "[[4, 7]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  20%|████████████████▍                                                                 | 30/150 [00:01<00:05, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take plate\n",
      "['jug', 'jug', 'measuring', 'pitcher', 'carafe', 'rinse']\n",
      "[0, 4, 105]\n",
      "21741 22090\n",
      "[(21829, 21993, 'take plate'),\n",
      " (21999, 22144, 'take packet of cookies'),\n",
      " (21648, 21781, 'take packets of cookies'),\n",
      " (21458, 21543, 'open microwave'),\n",
      " (21208, 21452, 'place cup on table')]\n",
      "P05-P05_03-21\n",
      "take jug\n",
      "[[5, 8]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  27%|█████████████████████▊                                                            | 40/150 [00:01<00:04, 26.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wash spoon\n",
      "['sponge', 'sponge', 'scrubber']\n",
      "[4, 7, 21]\n",
      "54571 55176\n",
      "[(54615, 55185, 'wash spoon'),\n",
      " (54519, 54561, 'take spoon'),\n",
      " (53712, 54409, 'wash wooden spoon'),\n",
      " (53610, 53666, 'take wooden spoon'),\n",
      " (51853, 53366, 'wash pot')]\n",
      "P05-P05_03-4\n",
      "wash sponge\n",
      "[[5, 11]]\n",
      "--------------------------------------------------\n",
      "open sweetcorn\n",
      "['can', 'can', 'tin', 'tomato']\n",
      "[2, 161, 87]\n",
      "34201 34480\n",
      "[(34254, 34402, 'open sweetcorn'),\n",
      " (34443, 34863, 'drain sweetcorn'),\n",
      " (34137, 34212, 'pick up sweetcorn'),\n",
      " (33372, 34094, 'spread chopped onion'),\n",
      " (33113, 33372, 'pick up onion')]\n",
      "P06-P06_05-444\n",
      "open can\n",
      "[[5, 8]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  40%|████████████████████████████████▊                                                 | 60/150 [00:02<00:05, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut garlic\n",
      "['knife', 'knife', 'mincing', 'using', 'blade', 'chopper', 'mezzaluna', 'moon', 'mezzaluna']\n",
      "[5, 45, 5]\n",
      "23219 23830\n",
      "[(23306, 23749, 'cut garlic'),\n",
      " (22945, 23263, 'peeling garlic'),\n",
      " (21216, 22434, 'peeling onion'),\n",
      " (24576, 25051, 'cut garlic'),\n",
      " (20581, 21210, 'peeling onion')]\n",
      "P12-P12_02-83\n",
      "cut knife\n",
      "[[4, 9]]\n",
      "--------------------------------------------------\n",
      "throw away garbage\n",
      "['package', 'package', 'cheese', 'bread', 'cooky', 'popcorn', 'mozzarella', 'parsley', 'salad', 'pasta', 'packaging', 'salad', 'bread', 'packet', 'cheese', 'pack', 'tortilla', 'tea', 'egg', 'wrapper', 'plastic', 'sausage', 'cookies', 'soup', 'bacon', 'oat', 'carton', 'beef', 'tea', 'meat', 'sachet', 'cookies', 'cheese', 'milk', 'flavour', 'sausage', 'cream', 'salt', 'salad', 'meat', 'pasta', 'fajita', 'wrap', 'spice', 'egg', 'cardboard', 'wrapping']\n",
      "[8, 77, 77]\n",
      "55791 56156\n",
      "[(55858, 56171, 'throw away garbage'),\n",
      " (54502, 54641, 'divide minced meats'),\n",
      " (54233, 54476, 'put minced meat on frying pan'),\n",
      " (53893, 54153, 'divide minced meats'),\n",
      " (56394, 57474, 'divide mince meat')]\n",
      "P12-P12_02-36\n",
      "throw package\n",
      "[[6, 13]]\n",
      "--------------------------------------------------\n",
      "put on cheese mixture\n",
      "['tray', 'tray', 'baking', 'baking', 'pizza', 'baking', 'tin']\n",
      "[1, 51, 63]\n",
      "22791 24940\n",
      "[(22885, 24895, 'put on cheese mixture'),\n",
      " (22716, 22879, 'take cheese'),\n",
      " (19653, 22696, 'distribute cheese mixture'),\n",
      " (19011, 19732, 'pour cheese mixture on pasta'),\n",
      " (15810, 17950, 'put lasagne plates on minced meat')]\n",
      "P12-P12_04-708\n",
      "put tray\n",
      "[[4, 8]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing TREK-150 Videos...:  42%|██████████████████████████████████▍                                               | 63/150 [00:02<00:06, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put dishes in dishwasher\n",
      "['knife', 'knife', 'mincing', 'using', 'blade', 'chopper', 'mezzaluna', 'moon', 'mezzaluna']\n",
      "[1, 7, 5]\n",
      "85071 85720\n",
      "[(85154, 85642, 'put dishes in dishwasher'),\n",
      " (85184, 85660, 'put in dishwasher'),\n",
      " (85332, 85784, 'put in dishwasher'),\n",
      " (83725, 85060, 'wash dishes'),\n",
      " (83830, 84118, 'wash dishes')]\n",
      "P12-P12_04-709\n",
      "put knife\n",
      "[[4, 9]]\n",
      "--------------------------------------------------\n",
      "open package\n",
      "['box', 'box', 'lunch', 'cereal', 'tea', 'salt', 'tupperware', 'lunchbox', 'case', 'mushroom', 'coffee', 'cheese', 'milk', 'rice', 'carrot', 'fruit', 'plastic', 'tub', 'plastic', 'eggs', 'fajita']\n",
      "[77, 141, 39]\n",
      "72755 74950\n",
      "[(72829, 74867, 'open package'),\n",
      " (74473, 75313, 'prepare roll of foil'),\n",
      " (74746, 75246, 'take foil'),\n",
      " (72418, 72726, 'dry hands'),\n",
      " (71976, 72414, 'wash hands')]\n",
      "P12-P12_04-600\n",
      "unwrap box\n",
      "[[7, 10]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  45%|█████████████████████████████████████▏                                            | 68/150 [00:03<00:07, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stir milk\n",
      "['cup', 'cup', 'coffee', 'measuring', 'small', 'mug', 'rinse', 'clean']\n",
      "[6, 43, 23]\n",
      "14342 14770\n",
      "[(14390, 14686, 'stir milk'),\n",
      " (14059, 14155, 'store sugar in cupboard'),\n",
      " (13085, 13576, 'pour sugar into cup'),\n",
      " (12451, 12586, 'close microwave'),\n",
      " (12237, 12466, 'pick up cup')]\n",
      "P13-P13_04-10\n",
      "mix cup\n",
      "[[4, 7]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  61%|██████████████████████████████████████████████████▎                               | 92/150 [00:04<00:03, 19.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wash the dish\n",
      "['box', 'box', 'lunch', 'cereal', 'tea', 'salt', 'tupperware', 'lunchbox', 'case', 'mushroom', 'coffee', 'cheese', 'milk', 'rice', 'carrot', 'fruit', 'plastic', 'tub', 'plastic', 'eggs', 'fajita']\n",
      "[4, 39, 39]\n",
      "3591 5830\n",
      "[(3569, 6207, 'wash the dish'),\n",
      " (3762, 4104, 'wash the dish'),\n",
      " (2888, 3675, 'wash the dish'),\n",
      " (2332, 2773, 'wash the chopsticks'),\n",
      " (1080, 2347, 'wash the pan')]\n",
      "P16-P16_03-151\n",
      "wash box\n",
      "[[5, 8]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  67%|██████████████████████████████████████████████████████▌                          | 101/150 [00:05<00:02, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put chicken into bowl\n",
      "['meat', 'meat', 'minced', 'meat', 'meat', 'mix', 'mincemeat', 'mince']\n",
      "[0, 26, 26]\n",
      "31761 32246\n",
      "[(31857, 32310, 'put chicken into bowl'),\n",
      " (31319, 31744, 'pour water'),\n",
      " (29628, 31259, 'still heat bacon'),\n",
      " (32326, 32424, 'put chicken into bowl'),\n",
      " (29604, 29856, 'still heat bacon')]\n",
      "P19-P19_04-148\n",
      "take meat\n",
      "[[5, 9]]\n",
      "--------------------------------------------------\n",
      "wash chicken\n",
      "['meat', 'meat', 'minced', 'meat', 'meat', 'mix', 'mincemeat', 'mince']\n",
      "[24, 23, 26]\n",
      "15861 16540\n",
      "[(15956, 16454, 'wash chicken'),\n",
      " (15855, 15952, 'put the chicken into bowl'),\n",
      " (16460, 16670, 'wash hands'),\n",
      " (14599, 15049, 'take chicken'),\n",
      " (16944, 17035, 'throw green bean into porridge')]\n",
      "P19-P19_04-169\n",
      "fill meat\n",
      "[[5, 9]]\n",
      "--------------------------------------------------\n",
      "using knife to open sauce container\n",
      "['package', 'package', 'cheese', 'bread', 'cooky', 'popcorn', 'mozzarella', 'parsley', 'salad', 'pasta', 'packaging', 'salad', 'bread', 'packet', 'cheese', 'pack', 'tortilla', 'tea', 'egg', 'wrapper', 'plastic', 'sausage', 'cookies', 'soup', 'bacon', 'oat', 'carton', 'beef', 'tea', 'meat', 'sachet', 'cookies', 'cheese', 'milk', 'flavour', 'sausage', 'cream', 'salt', 'salad', 'meat', 'pasta', 'fajita', 'wrap', 'spice', 'egg', 'cardboard', 'wrapping']\n",
      "[2, 77, 77]\n",
      "36291 37210\n",
      "[(36386, 37161, 'using knife to open sauce container'),\n",
      " (36375, 37128, 'opening sauce container'),\n",
      " (35871, 36325, 'opening sauce container'),\n",
      " (35529, 35754, 'take sauce out of fridge'),\n",
      " (35433, 35523, 'open fridge')]\n",
      "P21-P21_01-201\n",
      "open package\n",
      "[[5, 12]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  75%|████████████████████████████████████████████████████████████▍                    | 112/150 [00:06<00:02, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing the door\n",
      "['door:kitchen', 'kitchen']\n",
      "[3, 34, 34]\n",
      "17826 18040\n",
      "[(17787, 17963, 'closing the door'),\n",
      " (15387, 17781, 'cut the onion into the small piece'),\n",
      " (18199, 18349, 'opening the door'),\n",
      " (18382, 18489, 'adjust the chair'),\n",
      " (18920, 18967, 'open the tap')]\n",
      "P23-P23_03-243\n",
      "close door:kitchen\n",
      "[[6, 18]]\n",
      "--------------------------------------------------\n",
      "clean the bowl\n",
      "['colander', 'colander', 'pasta']\n",
      "[4, 42, 42]\n",
      "91491 92770\n",
      "[(91586, 92680, 'clean the bowl'),\n",
      " (92623, 92769, 'cleaning the bowl'),\n",
      " (88230, 91309, 'mixing the curry'),\n",
      " (92804, 92853, 'take the brush'),\n",
      " (93851, 94101, 'put the dust into dustbin')]\n",
      "P23-P23_04-389\n",
      "wash colander\n",
      "[[5, 13]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  82%|██████████████████████████████████████████████████████████████████▍              | 123/150 [00:06<00:01, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put on detergent\n",
      "['sponge', 'sponge', 'scrubber']\n",
      "[4, 21, 21]\n",
      "36291 36700\n",
      "[(36390, 36622, 'put on detergent'),\n",
      " (36291, 36385, 'put down knife'),\n",
      " (35680, 36285, 'clean knife'),\n",
      " (34887, 35625, 'put on detergent'),\n",
      " (35163, 35390, 'rinse sponge')]\n",
      "P25-P25_09-2061\n",
      "wash sponge\n",
      "[[5, 11]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...: 100%|█████████████████████████████████████████████████████████████████████████████████| 150/150 [00:07<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95094 95094\n",
      "Saving coco file to: /local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\n"
     ]
    }
   ],
   "source": [
    "# Inits.\n",
    "image_id_accum = 0\n",
    "annot_id_accum = 0\n",
    "# frame_num_step = 10\n",
    "frame_num_step = 1\n",
    "coco_format_images = []\n",
    "coco_format_annots = []\n",
    "\n",
    "\n",
    "# Testing start frame dict.\n",
    "trek150_data_root = \"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150\"\n",
    "start_frames_dict = json.load(open(\n",
    "    \"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines\"\n",
    "    \"/LTMU-H/TREK-150-toolkit/first_mistakes.json\"\n",
    "))\n",
    "per_video_start_frames = {}\n",
    "for video_id in video_ids:\n",
    "    if video_id not in start_frames_dict:\n",
    "        per_video_start_frames[video_id] = None\n",
    "    else:\n",
    "        per_video_start_frames[video_id] = int(start_frames_dict[video_id])\n",
    "########\n",
    "per_video_start_frames = None\n",
    "\n",
    "\n",
    "for video_id in tqdm(video_ids, desc=\"Processing TREK-150 Videos...\"):\n",
    "    ek_video_id = video_id.split(\"-\")[1]\n",
    "    frame_narration_list = print_ek_video_narrations(\n",
    "        ek_video_id,\n",
    "        epic_kitchens_data,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    # if video_id == \"P03-P03_04-57\":\n",
    "    if video_id == \"P03-P03_04-48\":\n",
    "        # verbose = True\n",
    "        verbose = False\n",
    "    else:\n",
    "        verbose = False\n",
    "    \n",
    "    image_id_accum, annot_id_accum = process_one_trek150_video(\n",
    "        video_id=video_id,\n",
    "        trek150_data_root=\"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150\",\n",
    "        frame_num_step=frame_num_step,\n",
    "        image_id_accum=image_id_accum,\n",
    "        annot_id_accum=annot_id_accum,\n",
    "        coco_format_images=coco_format_images,\n",
    "        coco_format_annots=coco_format_annots,\n",
    "        narrations_info_dict=frame_narration_list,\n",
    "        token_positive_method=\"gt\",\n",
    "        action_class_mappings=action_class_mappings,\n",
    "        per_video_start_frames=per_video_start_frames,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "print(len(coco_format_images), len(coco_format_annots))\n",
    "\n",
    "save_coco_file(\n",
    "    coco_format_images,\n",
    "    coco_format_annots,\n",
    "    output_root=\"/local1/telinwu/research/resources/TREK-150/coco_annotations\",\n",
    "    # output_name=\"trek150_stepwise_10_frames_narrated_gt\",\n",
    "    output_name=\"trek150_all_frames_with_first_mdnet_fail_narrated_gt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb0deb69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...:  46%|█████████████████████████████████████▎                                           | 69/150 [00:00<00:00, 345.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn on tap\n",
      "['pan', 'pan', 'sauce', 'frying', 'cake', 'saucepan', 'empty', 'small', 'wok', 'scour', 'content']\n",
      "[11, 3, 1]\n",
      "22440 22690\n",
      "[(22391, 22597, 'turn on tap'),\n",
      " (22663, 22707, 'turn off tap'),\n",
      " (22307, 22358, 'push bin back'),\n",
      " (22100, 22301, 'put lid on bin'),\n",
      " (21801, 22121, 'open bag')]\n",
      "P03-P03_02-56\n",
      "dry pan\n",
      "[[4, 7]]\n",
      "--------------------------------------------------\n",
      "take plate\n",
      "['jug', 'jug', 'measuring', 'pitcher', 'carafe', 'rinse']\n",
      "[0, 4, 105]\n",
      "21741 22090\n",
      "[(21829, 21993, 'take plate'),\n",
      " (21999, 22144, 'take packet of cookies'),\n",
      " (21648, 21781, 'take packets of cookies'),\n",
      " (21458, 21543, 'open microwave'),\n",
      " (21208, 21452, 'place cup on table')]\n",
      "P05-P05_03-21\n",
      "take jug\n",
      "[[5, 8]]\n",
      "--------------------------------------------------\n",
      "wash spoon\n",
      "['sponge', 'sponge', 'scrubber']\n",
      "[4, 7, 21]\n",
      "54571 55176\n",
      "[(54615, 55185, 'wash spoon'),\n",
      " (54519, 54561, 'take spoon'),\n",
      " (53712, 54409, 'wash wooden spoon'),\n",
      " (53610, 53666, 'take wooden spoon'),\n",
      " (51853, 53366, 'wash pot')]\n",
      "P05-P05_03-4\n",
      "wash sponge\n",
      "[[5, 11]]\n",
      "--------------------------------------------------\n",
      "open sweetcorn\n",
      "['can', 'can', 'tin', 'tomato']\n",
      "[2, 161, 87]\n",
      "34201 34480\n",
      "[(34254, 34402, 'open sweetcorn'),\n",
      " (34443, 34863, 'drain sweetcorn'),\n",
      " (34137, 34212, 'pick up sweetcorn'),\n",
      " (33372, 34094, 'spread chopped onion'),\n",
      " (33113, 33372, 'pick up onion')]\n",
      "P06-P06_05-444\n",
      "open can\n",
      "[[5, 8]]\n",
      "--------------------------------------------------\n",
      "cut garlic\n",
      "['knife', 'knife', 'mincing', 'using', 'blade', 'chopper', 'mezzaluna', 'moon', 'mezzaluna']\n",
      "[5, 45, 5]\n",
      "23219 23830\n",
      "[(23306, 23749, 'cut garlic'),\n",
      " (22945, 23263, 'peeling garlic'),\n",
      " (21216, 22434, 'peeling onion'),\n",
      " (24576, 25051, 'cut garlic'),\n",
      " (20581, 21210, 'peeling onion')]\n",
      "P12-P12_02-83\n",
      "cut knife\n",
      "[[4, 9]]\n",
      "--------------------------------------------------\n",
      "throw away garbage\n",
      "['package', 'package', 'cheese', 'bread', 'cooky', 'popcorn', 'mozzarella', 'parsley', 'salad', 'pasta', 'packaging', 'salad', 'bread', 'packet', 'cheese', 'pack', 'tortilla', 'tea', 'egg', 'wrapper', 'plastic', 'sausage', 'cookies', 'soup', 'bacon', 'oat', 'carton', 'beef', 'tea', 'meat', 'sachet', 'cookies', 'cheese', 'milk', 'flavour', 'sausage', 'cream', 'salt', 'salad', 'meat', 'pasta', 'fajita', 'wrap', 'spice', 'egg', 'cardboard', 'wrapping']\n",
      "[8, 77, 77]\n",
      "55791 56156\n",
      "[(55858, 56171, 'throw away garbage'),\n",
      " (54502, 54641, 'divide minced meats'),\n",
      " (54233, 54476, 'put minced meat on frying pan'),\n",
      " (53893, 54153, 'divide minced meats'),\n",
      " (56394, 57474, 'divide mince meat')]\n",
      "P12-P12_02-36\n",
      "throw package\n",
      "[[6, 13]]\n",
      "--------------------------------------------------\n",
      "put on cheese mixture\n",
      "['tray', 'tray', 'baking', 'baking', 'pizza', 'baking', 'tin']\n",
      "[1, 51, 63]\n",
      "22791 24940\n",
      "[(22885, 24895, 'put on cheese mixture'),\n",
      " (22716, 22879, 'take cheese'),\n",
      " (19653, 22696, 'distribute cheese mixture'),\n",
      " (19011, 19732, 'pour cheese mixture on pasta'),\n",
      " (15810, 17950, 'put lasagne plates on minced meat')]\n",
      "P12-P12_04-708\n",
      "put tray\n",
      "[[4, 8]]\n",
      "--------------------------------------------------\n",
      "put dishes in dishwasher\n",
      "['knife', 'knife', 'mincing', 'using', 'blade', 'chopper', 'mezzaluna', 'moon', 'mezzaluna']\n",
      "[1, 7, 5]\n",
      "85071 85720\n",
      "[(85154, 85642, 'put dishes in dishwasher'),\n",
      " (85184, 85660, 'put in dishwasher'),\n",
      " (85332, 85784, 'put in dishwasher'),\n",
      " (83725, 85060, 'wash dishes'),\n",
      " (83830, 84118, 'wash dishes')]\n",
      "P12-P12_04-709\n",
      "put knife\n",
      "[[4, 9]]\n",
      "--------------------------------------------------\n",
      "open package\n",
      "['box', 'box', 'lunch', 'cereal', 'tea', 'salt', 'tupperware', 'lunchbox', 'case', 'mushroom', 'coffee', 'cheese', 'milk', 'rice', 'carrot', 'fruit', 'plastic', 'tub', 'plastic', 'eggs', 'fajita']\n",
      "[77, 141, 39]\n",
      "72755 74950\n",
      "[(72829, 74867, 'open package'),\n",
      " (74473, 75313, 'prepare roll of foil'),\n",
      " (74746, 75246, 'take foil'),\n",
      " (72418, 72726, 'dry hands'),\n",
      " (71976, 72414, 'wash hands')]\n",
      "P12-P12_04-600\n",
      "unwrap box\n",
      "[[7, 10]]\n",
      "--------------------------------------------------\n",
      "stir milk\n",
      "['cup', 'cup', 'coffee', 'measuring', 'small', 'mug', 'rinse', 'clean']\n",
      "[6, 43, 23]\n",
      "14342 14770\n",
      "[(14390, 14686, 'stir milk'),\n",
      " (14059, 14155, 'store sugar in cupboard'),\n",
      " (13085, 13576, 'pour sugar into cup'),\n",
      " (12451, 12586, 'close microwave'),\n",
      " (12237, 12466, 'pick up cup')]\n",
      "P13-P13_04-10\n",
      "mix cup\n",
      "[[4, 7]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TREK-150 Videos...: 100%|████████████████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 382.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wash the dish\n",
      "['box', 'box', 'lunch', 'cereal', 'tea', 'salt', 'tupperware', 'lunchbox', 'case', 'mushroom', 'coffee', 'cheese', 'milk', 'rice', 'carrot', 'fruit', 'plastic', 'tub', 'plastic', 'eggs', 'fajita']\n",
      "[4, 39, 39]\n",
      "3591 5830\n",
      "[(3569, 6207, 'wash the dish'),\n",
      " (3762, 4104, 'wash the dish'),\n",
      " (2888, 3675, 'wash the dish'),\n",
      " (2332, 2773, 'wash the chopsticks'),\n",
      " (1080, 2347, 'wash the pan')]\n",
      "P16-P16_03-151\n",
      "wash box\n",
      "[[5, 8]]\n",
      "--------------------------------------------------\n",
      "put chicken into bowl\n",
      "['meat', 'meat', 'minced', 'meat', 'meat', 'mix', 'mincemeat', 'mince']\n",
      "[0, 26, 26]\n",
      "31761 32246\n",
      "[(31857, 32310, 'put chicken into bowl'),\n",
      " (31319, 31744, 'pour water'),\n",
      " (29628, 31259, 'still heat bacon'),\n",
      " (32326, 32424, 'put chicken into bowl'),\n",
      " (29604, 29856, 'still heat bacon')]\n",
      "P19-P19_04-148\n",
      "take meat\n",
      "[[5, 9]]\n",
      "--------------------------------------------------\n",
      "wash chicken\n",
      "['meat', 'meat', 'minced', 'meat', 'meat', 'mix', 'mincemeat', 'mince']\n",
      "[24, 23, 26]\n",
      "15861 16540\n",
      "[(15956, 16454, 'wash chicken'),\n",
      " (15855, 15952, 'put the chicken into bowl'),\n",
      " (16460, 16670, 'wash hands'),\n",
      " (14599, 15049, 'take chicken'),\n",
      " (16944, 17035, 'throw green bean into porridge')]\n",
      "P19-P19_04-169\n",
      "fill meat\n",
      "[[5, 9]]\n",
      "--------------------------------------------------\n",
      "using knife to open sauce container\n",
      "['package', 'package', 'cheese', 'bread', 'cooky', 'popcorn', 'mozzarella', 'parsley', 'salad', 'pasta', 'packaging', 'salad', 'bread', 'packet', 'cheese', 'pack', 'tortilla', 'tea', 'egg', 'wrapper', 'plastic', 'sausage', 'cookies', 'soup', 'bacon', 'oat', 'carton', 'beef', 'tea', 'meat', 'sachet', 'cookies', 'cheese', 'milk', 'flavour', 'sausage', 'cream', 'salt', 'salad', 'meat', 'pasta', 'fajita', 'wrap', 'spice', 'egg', 'cardboard', 'wrapping']\n",
      "[2, 77, 77]\n",
      "36291 37210\n",
      "[(36386, 37161, 'using knife to open sauce container'),\n",
      " (36375, 37128, 'opening sauce container'),\n",
      " (35871, 36325, 'opening sauce container'),\n",
      " (35529, 35754, 'take sauce out of fridge'),\n",
      " (35433, 35523, 'open fridge')]\n",
      "P21-P21_01-201\n",
      "open package\n",
      "[[5, 12]]\n",
      "--------------------------------------------------\n",
      "closing the door\n",
      "['door:kitchen', 'kitchen']\n",
      "[3, 34, 34]\n",
      "17826 18040\n",
      "[(17787, 17963, 'closing the door'),\n",
      " (15387, 17781, 'cut the onion into the small piece'),\n",
      " (18199, 18349, 'opening the door'),\n",
      " (18382, 18489, 'adjust the chair'),\n",
      " (18920, 18967, 'open the tap')]\n",
      "P23-P23_03-243\n",
      "close door:kitchen\n",
      "[[6, 18]]\n",
      "--------------------------------------------------\n",
      "clean the bowl\n",
      "['colander', 'colander', 'pasta']\n",
      "[4, 42, 42]\n",
      "91491 92770\n",
      "[(91586, 92680, 'clean the bowl'),\n",
      " (92623, 92769, 'cleaning the bowl'),\n",
      " (88230, 91309, 'mixing the curry'),\n",
      " (92804, 92853, 'take the brush'),\n",
      " (93851, 94101, 'put the dust into dustbin')]\n",
      "P23-P23_04-389\n",
      "wash colander\n",
      "[[5, 13]]\n",
      "--------------------------------------------------\n",
      "put on detergent\n",
      "['sponge', 'sponge', 'scrubber']\n",
      "[4, 21, 21]\n",
      "36291 36700\n",
      "[(36390, 36622, 'put on detergent'),\n",
      " (36291, 36385, 'put down knife'),\n",
      " (35680, 36285, 'clean knife'),\n",
      " (34887, 35625, 'put on detergent'),\n",
      " (35163, 35390, 'rinse sponge')]\n",
      "P25-P25_09-2061\n",
      "wash sponge\n",
      "[[5, 11]]\n",
      "--------------------------------------------------\n",
      "150 150\n",
      "Saving coco file to: /local1/telinwu/research/resources/TREK-150/coco_annotations/trek150_1st_frame_only_narrated_gt.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inits.\n",
    "image_id_accum = 0\n",
    "annot_id_accum = 0\n",
    "frame_num_step = 100000000\n",
    "coco_format_images = []\n",
    "coco_format_annots = []\n",
    "per_video_start_frames = None\n",
    "\n",
    "\n",
    "for video_id in tqdm(video_ids, desc=\"Processing TREK-150 Videos...\"):\n",
    "    ek_video_id = video_id.split(\"-\")[1]\n",
    "    frame_narration_list = print_ek_video_narrations(\n",
    "        ek_video_id,\n",
    "        epic_kitchens_data,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    # if video_id == \"P03-P03_04-57\":\n",
    "    if video_id == \"P03-P03_04-48\":\n",
    "        # verbose = True\n",
    "        verbose = False\n",
    "    else:\n",
    "        verbose = False\n",
    "    \n",
    "    image_id_accum, annot_id_accum = process_one_trek150_video(\n",
    "        video_id=video_id,\n",
    "        trek150_data_root=\"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150\",\n",
    "        frame_num_step=frame_num_step,\n",
    "        image_id_accum=image_id_accum,\n",
    "        annot_id_accum=annot_id_accum,\n",
    "        coco_format_images=coco_format_images,\n",
    "        coco_format_annots=coco_format_annots,\n",
    "        narrations_info_dict=frame_narration_list,\n",
    "        token_positive_method=\"gt\",\n",
    "        action_class_mappings=action_class_mappings,\n",
    "        per_video_start_frames=per_video_start_frames,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "print(len(coco_format_images), len(coco_format_annots))\n",
    "\n",
    "save_coco_file(\n",
    "    coco_format_images,\n",
    "    coco_format_annots,\n",
    "    output_root=\"/local1/telinwu/research/resources/TREK-150/coco_annotations\",\n",
    "    output_name=\"trek150_1st_frame_only_narrated_gt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631cd048",
   "metadata": {},
   "source": [
    "# Distribute GPT Results to Other Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8d12bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dcd80195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /local1/telinwu/research/resources/TREK-150/paper_data/narrated/gpt_v2_25percent_prepost/gpt_trek150_stepwise_10_frames_narrated_gt.json\n",
      "Saving to: /local1/telinwu/research/resources/TREK-150/paper_data/narrated/gpt_v2_25percent_prepost/gpt_trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\n"
     ]
    }
   ],
   "source": [
    "init_gpt_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/paper_data/narrated\"\n",
    "    # \"/gpt_v1/gpt_trek150_1st_frame_only_narrated_gt.json\"\n",
    "    \"/gpt_v2/gpt_trek150_1st_frame_only_narrated_gt.json\"\n",
    ")\n",
    "\n",
    "files_to_insert = [\n",
    "    (\n",
    "        \"/local1/telinwu/research/resources/TREK-150/paper_data/narrated\"\n",
    "        \"/gt_srl_arg1/trek150_stepwise_10_frames_narrated_gt.json\"\n",
    "    ),\n",
    "    (\n",
    "        \"/local1/telinwu/research/resources/TREK-150/paper_data/narrated\"\n",
    "        \"/gt_srl_arg1/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "gpt_data = json.load(open(init_gpt_file))\n",
    "gpt_symb_dict = {}\n",
    "for image in gpt_data[\"images\"]:\n",
    "    file_name = image[\"file_name\"]\n",
    "    video_uid = file_name.split(\"/\")[0]\n",
    "    gpt_symb_dict[video_uid] = image\n",
    "\n",
    "gpt_file_folder = \"/\".join(init_gpt_file.split(\"/\")[:-1])\n",
    "folder_suffix = None\n",
    "folder_suffix = \"25percent_prepost\"\n",
    "\n",
    "if folder_suffix is not None:\n",
    "    gpt_file_folder += \"_{}\".format(folder_suffix)\n",
    "if not os.path.exists(gpt_file_folder):\n",
    "    os.makedirs(gpt_file_folder)\n",
    "\n",
    "for f in files_to_insert:\n",
    "    file_name = f.split(\"/\")[-1]\n",
    "    new_file_name = \"gpt_\" + file_name\n",
    "    new_file_path = os.path.join(gpt_file_folder, new_file_name)\n",
    "    \n",
    "    trek_data = json.load(open(f))\n",
    "    trek_images = trek_data[\"images\"]\n",
    "    \n",
    "    per_video_frames = {}\n",
    "    for image in trek_images:\n",
    "        file_name = image[\"file_name\"]\n",
    "        video_uid = file_name.split(\"/\")[0]\n",
    "        video_frame_num = int(file_name.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "        if video_uid not in per_video_frames:\n",
    "            per_video_frames[video_uid] = {}\n",
    "        per_video_frames[video_uid][video_frame_num] = image\n",
    "    \n",
    "    for video_uid in per_video_frames:\n",
    "        frame_nums = sorted(list(per_video_frames[video_uid].keys()))\n",
    "        frames_diff = frame_nums[-1] - frame_nums[0]\n",
    "        first_K_pre = 10\n",
    "        last_K_post = 10\n",
    "        first_K_pre = int(frames_diff * 0.25)\n",
    "        last_K_post = int(frames_diff * 0.25)\n",
    "        for frame_num in frame_nums:\n",
    "            if frame_num <= frame_nums[0] + first_K_pre:\n",
    "                current_frame_type = \"pre\"\n",
    "            elif frame_num >= frame_nums[-1] - last_K_post:\n",
    "                current_frame_type = \"post\"\n",
    "            else:\n",
    "                current_frame_type = \"pnr\"\n",
    "            gpt_image = copy.deepcopy(gpt_symb_dict[video_uid])\n",
    "            if \"symbolic\" not in gpt_image:\n",
    "                print(video_uid)\n",
    "            symb = gpt_image[\"symbolic\"]\n",
    "            symb[\"current_frame_type\"] = current_frame_type\n",
    "            curr_image = per_video_frames[video_uid][frame_num]\n",
    "            curr_image[\"symbolic\"] = symb\n",
    "            curr_image[\"caption\"] = gpt_image[\"caption\"]\n",
    "            curr_image[\"tokens_positive_eval\"] = gpt_image[\"tokens_positive_eval\"]\n",
    "            curr_image[\"gpt_pass\"] = gpt_image[\"gpt_pass\"]\n",
    "        pass\n",
    "    \n",
    "    images_to_insert = []\n",
    "    for video_uid in per_video_frames:\n",
    "        frame_nums = sorted(list(per_video_frames[video_uid].keys()))\n",
    "        for frame_num in frame_nums:\n",
    "            images_to_insert.append(per_video_frames[video_uid][frame_num])\n",
    "    images_to_insert = sorted(images_to_insert, key=lambda x: x[\"id\"])\n",
    "    \n",
    "    trek_data[\"images\"] = images_to_insert\n",
    "    json.dump(\n",
    "        trek_data,\n",
    "        open(new_file_path, \"w\"),\n",
    "        indent=4,\n",
    "    )\n",
    "    \n",
    "    print(\"Saving to: {}\".format(new_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e18d5d",
   "metadata": {},
   "source": [
    "### For Full Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_ref_file = (\n",
    "    \"/local1/telinwu/research/resources/TREK-150/paper_data\"\n",
    "    \"/narrated/gt_srl_arg1/trek150_1st_frame_only_narrated_gt.json\"\n",
    ")\n",
    "\n",
    "output_file = init_ref_file.replace(\"gt_srl_arg1\", \"full_sentence\").replace(\"_gt.json\", \"_full_sentence.json\")\n",
    "\n",
    "init_data = json.load(open(init_ref_file))\n",
    "for image_idx in range(len(init_data[\"images\"])):\n",
    "    caption = init_data[\"images\"][image_idx][\"caption\"]\n",
    "    new_tokens_positive_eval = [[[0, len(caption)]]]\n",
    "    init_data[\"images\"][image_idx][\"tokens_positive_eval\"] = new_tokens_positive_eval\n",
    "json.dump(\n",
    "    init_data,\n",
    "    open(output_file, \"w\"),\n",
    "    indent=4,\n",
    ")\n",
    "print(\"Saving to: {}\".format(output_file))\n",
    "\n",
    "init_new_file = output_file\n",
    "init_new_data = json.load(open(init_new_file))\n",
    "init_data_dict = {}\n",
    "for image in init_new_data[\"images\"]:\n",
    "    file_name = image[\"file_name\"]\n",
    "    video_uid = file_name.split(\"/\")[0]\n",
    "    init_data_dict[video_uid] = image\n",
    "\n",
    "files_to_insert = [\n",
    "    (\n",
    "        \"/local1/telinwu/research/resources/TREK-150/paper_data/narrated\"\n",
    "        \"/gt_srl_arg1/trek150_stepwise_10_frames_narrated_gt.json\"\n",
    "    ),\n",
    "    (\n",
    "        \"/local1/telinwu/research/resources/TREK-150/paper_data/narrated\"\n",
    "        \"/gt_srl_arg1/trek150_all_frames_with_first_mdnet_fail_narrated_gt.json\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "file_folder = \"/\".join(init_new_file.split(\"/\")[:-1])\n",
    "\n",
    "for f in files_to_insert:\n",
    "    file_name = f.split(\"/\")[-1]\n",
    "    new_file_name = file_name.replace(\"_gt.json\", \"_full_sentence.json\")\n",
    "    new_file_path = os.path.join(file_folder, new_file_name)\n",
    "    \n",
    "    trek_data = json.load(open(f))\n",
    "    trek_images = trek_data[\"images\"]\n",
    "    \n",
    "    per_video_frames = {}\n",
    "    for image in trek_images:\n",
    "        file_name = image[\"file_name\"]\n",
    "        video_uid = file_name.split(\"/\")[0]\n",
    "        video_frame_num = int(file_name.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "        if video_uid not in per_video_frames:\n",
    "            per_video_frames[video_uid] = {}\n",
    "        per_video_frames[video_uid][video_frame_num] = image\n",
    "    \n",
    "    for video_uid in per_video_frames:\n",
    "        frame_nums = sorted(list(per_video_frames[video_uid].keys()))\n",
    "        for frame_num in frame_nums:\n",
    "            curr_image = per_video_frames[video_uid][frame_num]\n",
    "            curr_image[\"tokens_positive_eval\"] = init_data_dict[video_uid][\"tokens_positive_eval\"]\n",
    "        pass\n",
    "    \n",
    "    images_to_insert = []\n",
    "    for video_uid in per_video_frames:\n",
    "        frame_nums = sorted(list(per_video_frames[video_uid].keys()))\n",
    "        for frame_num in frame_nums:\n",
    "            images_to_insert.append(per_video_frames[video_uid][frame_num])\n",
    "    images_to_insert = sorted(images_to_insert, key=lambda x: x[\"id\"])\n",
    "    \n",
    "    trek_data[\"images\"] = images_to_insert\n",
    "    json.dump(\n",
    "        trek_data,\n",
    "        open(new_file_path, \"w\"),\n",
    "        indent=4,\n",
    "    )\n",
    "    \n",
    "    print(\"Saving to: {}\".format(new_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471ce1e",
   "metadata": {},
   "source": [
    "# Make SCOD Tracking (Use `PNR` to **track** `Post`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "924a052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_gt_file = (\n",
    "    \"/local1/telinwu/research/resources/Ego4D/ego4d_scod_challenge/paper_data/all_frames/narrated\"\n",
    "    \"/gpt_v3_srl_arg1_with_tool/val_scod_all_frames_narrated_gpt_v3_srl_arg1_with_tool.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"/local1/telinwu/research/resources/Ego4D/ego4d_scod_challenge/paper_models/all_frames/narrated\"\n",
    "    \"/gpt_v3_srl_arg1_with_tool\"\n",
    "    \"/ego4d_scod_all_frames_narrated_gpt_v3_srl_arg1_with_tool_drop_null_ooc_tool_symb_conds_mask_no_comma\"\n",
    "    \"/eval_at_45K/eval/model_0045000/inference/narrated_ego4d_test/bbox.json\"\n",
    ")\n",
    "\n",
    "\n",
    "coco_gt_data = json.load(open(coco_gt_file))\n",
    "coco_pred_data = json.load(open(coco_pred_file))\n",
    "\n",
    "coco_gt_id_mapping = {}\n",
    "for coco_gt_image in coco_gt_data[\"images\"]:\n",
    "    coco_gt_id_mapping[coco_gt_image[\"id\"]] = coco_gt_image[\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6f16eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1070544/1070544 [00:09<00:00, 117220.16it/s]\n"
     ]
    }
   ],
   "source": [
    "trek150_results = {}\n",
    "coco_preds = json.load(open(coco_pred_file))\n",
    "for coco_pred in tqdm(coco_preds, desc=\"COCO\"):\n",
    "    image_id = coco_pred[\"image_id\"]\n",
    "    file_name = coco_gt_id_mapping[image_id]\n",
    "    video_id = file_name.split(\"/\")[0]\n",
    "    image_name = file_name.split(\"/\")[-1]\n",
    "    frame_cnt = image_name.split(\"_\")[-1].split(\".\")[0]\n",
    "    frame_cnt_int = int(frame_cnt)\n",
    "    if video_id not in trek150_results:\n",
    "        trek150_results[video_id] = {}\n",
    "    frame_key = frame_cnt\n",
    "    if frame_key not in trek150_results[video_id]:\n",
    "        trek150_results[video_id][frame_key] = {\n",
    "            \"bboxes\": [],\n",
    "            \"scores\": [],\n",
    "            \"scored_bboxes\": [],\n",
    "        }\n",
    "    trek150_results[video_id][frame_key][\"bboxes\"].append(coco_pred[\"bbox\"])\n",
    "    trek150_results[video_id][frame_key][\"scores\"].append(coco_pred[\"score\"])\n",
    "    trek150_results[video_id][frame_key][\"scored_bboxes\"].append((coco_pred[\"score\"], coco_pred[\"bbox\"]))\n",
    "    \n",
    "for video_id in trek150_results:\n",
    "    for frame_key in trek150_results[video_id]:\n",
    "        trek150_results[video_id][frame_key][\"bboxes\"] = np.asarray(\n",
    "            trek150_results[video_id][frame_key][\"bboxes\"]\n",
    "        )\n",
    "        trek150_results[video_id][frame_key][\"scores\"] = np.asarray(\n",
    "            trek150_results[video_id][frame_key][\"scores\"]\n",
    "        )\n",
    "        scored_bboxes = sorted(\n",
    "            trek150_results[video_id][frame_key][\"scored_bboxes\"],\n",
    "            reverse=True\n",
    "        )\n",
    "        scores = [s for s, b in scored_bboxes]\n",
    "        bboxes = [b for s, b in scored_bboxes]\n",
    "        trek150_results[video_id][frame_key][\"bboxes\"] = np.asarray(bboxes)\n",
    "        trek150_results[video_id][frame_key][\"scores\"] = np.asarray(scores)\n",
    "        del trek150_results[video_id][frame_key][\"scored_bboxes\"]\n",
    "\n",
    "pickle.dump(\n",
    "    trek150_results,\n",
    "    open(\n",
    "        (\n",
    "            \"/local1/telinwu/research/resources/TREK-150/paper_data/scod_track\"\n",
    "            \"/use_pnr_to_track_post/candidate_boxes.pickle\"\n",
    "        ),\n",
    "        \"wb\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ca17f6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tracking: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 12800/12800 [00:01<00:00, 7402.63it/s]\n"
     ]
    }
   ],
   "source": [
    "scod_track_root_folder = \"/local1/telinwu/research/resources/TREK-150/paper_data/scod_track/use_pnr_to_track_post\"\n",
    "clip_folder = os.path.join(scod_track_root_folder, \"clips\")\n",
    "\n",
    "image_id_annots_dict = {}\n",
    "for annot in coco_gt_data[\"annotations\"]:\n",
    "    image_id = annot[\"image_id\"]\n",
    "    if image_id not in image_id_annots_dict:\n",
    "        image_id_annots_dict[image_id] = []\n",
    "    image_id_annots_dict[image_id].append(annot)\n",
    "\n",
    "pnr_and_post_images = []\n",
    "curr_tuple = []\n",
    "for image in coco_gt_data[\"images\"]:\n",
    "    ego4d_scod_id = image[\"ego4d_scod_id\"]\n",
    "    if \"pre\" in ego4d_scod_id:\n",
    "        if len(curr_tuple) > 0:\n",
    "            pnr_and_post_images.append(curr_tuple)\n",
    "        curr_tuple = []\n",
    "        continue\n",
    "    if \"pnr\" in ego4d_scod_id:\n",
    "        curr_tuple.append(image)\n",
    "    if (\n",
    "        \"post\" in ego4d_scod_id\n",
    "        and \"pnr\" in curr_tuple[-1][\"ego4d_scod_id\"]\n",
    "    ):\n",
    "        curr_tuple.append(image)\n",
    "\n",
    "clip_folder_names = []\n",
    "for frame_tuple in tqdm(pnr_and_post_images, desc=\"Tracking\"):\n",
    "    assert len(frame_tuple) == 2\n",
    "    pnr_frame, post_frame = frame_tuple\n",
    "    pnr_frame_scod_id, post_frame_scod_id = pnr_frame[\"ego4d_scod_id\"], post_frame[\"ego4d_scod_id\"]\n",
    "    pnr_image_id, post_image_id = pnr_frame[\"id\"], post_frame[\"id\"]\n",
    "    if (\n",
    "        pnr_image_id not in image_id_annots_dict\n",
    "        or\n",
    "        post_image_id not in image_id_annots_dict\n",
    "    ):\n",
    "        continue\n",
    "    pnr_annot, post_annot = image_id_annots_dict[pnr_image_id], image_id_annots_dict[post_image_id]\n",
    "    pnr_annot =  [x for x in pnr_annot if x[\"category_id\"] == 1]\n",
    "    post_annot = [x for x in post_annot if x[\"category_id\"] == 1]\n",
    "    if (\n",
    "        len(pnr_annot) <= 0\n",
    "        or\n",
    "        len(post_annot) <= 0\n",
    "    ):\n",
    "        continue\n",
    "    pnr_annot, post_annot = pnr_annot[0], post_annot[0]\n",
    "    pnr_gt_bbox  = pnr_annot[\"bbox\"]\n",
    "    post_gt_bbox = post_annot[\"bbox\"]\n",
    "    pnr_frame_name  = pnr_frame[\"file_name\"]\n",
    "    post_frame_name = post_frame[\"file_name\"]\n",
    "    \n",
    "    video_uid = pnr_frame_name.split(\"/\")[0]\n",
    "    pnr_frame_num =  pnr_frame_name.split(\"/\")[-1].split(\".\")[0]\n",
    "    post_frame_num = post_frame_name.split(\"/\")[-1].split(\".\")[0]\n",
    "    clip_folder_name = \"{}_pnr_{}_post_{}\".format(video_uid, pnr_frame_num, post_frame_num)\n",
    "    clip_folder_path = os.path.join(clip_folder, clip_folder_name)\n",
    "    if os.path.exists(clip_folder_path):\n",
    "        shutil.rmtree(clip_folder_path)\n",
    "    os.makedirs(clip_folder_path)\n",
    "    clip_folder_names.append(clip_folder_name)\n",
    "    \n",
    "    groundtruth_rects = [\n",
    "        \",\".join([str(x) for x in pnr_gt_bbox]),\n",
    "        \",\".join([str(x) for x in post_gt_bbox]),\n",
    "    ]\n",
    "    groundtruth_rects_file = open(os.path.join(clip_folder_path, \"groundtruth_rect.txt\"), \"w\")\n",
    "    for groundtruth_rect in groundtruth_rects:\n",
    "        groundtruth_rects_file.write(groundtruth_rect+\"\\n\")\n",
    "    groundtruth_rects_file.close()\n",
    "    \n",
    "    frame_names = [\n",
    "        pnr_frame_name,\n",
    "        post_frame_name,\n",
    "    ]\n",
    "    frame_file = open(os.path.join(clip_folder_path, \"frames.txt\"), \"w\")\n",
    "    for frame_name in frame_names:\n",
    "        frame_file.write(frame_name+\"\\n\")\n",
    "    frame_file.close()\n",
    "\n",
    "sequences_file = open(os.path.join(scod_track_root_folder, \"sequences.txt\"), \"w\")\n",
    "for clip_folder_name in clip_folder_names:\n",
    "    sequences_file.write(clip_folder_name+\"\\n\")\n",
    "sequences_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff1abc",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "84806ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndarray_coco_results(coco_pred_file):\n",
    "    # [Nx7] where each row contains {imageID,x1,y1,w,h,score,class}\n",
    "    if type(coco_pred_file) == str:\n",
    "        preds = json.load(open(coco_pred_file))\n",
    "    else:\n",
    "        preds = coco_pred_file\n",
    "    arrs = []\n",
    "    for pred in preds:\n",
    "        image_id = pred[\"image_id\"]\n",
    "        x1 = pred[\"bbox\"][0]\n",
    "        y1 = pred[\"bbox\"][1]\n",
    "        w  = pred[\"bbox\"][2]\n",
    "        h  = pred[\"bbox\"][3]\n",
    "        score = pred[\"score\"]\n",
    "        label = pred[\"category_id\"]\n",
    "        arr = [image_id, x1, y1, w, h, score, label]\n",
    "        arrs.append(arr)\n",
    "    return np.asarray(arrs)\n",
    "\n",
    "\n",
    "def naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file,\n",
    "    coco_pred_file,\n",
    "    original_coco_gt_file=None,\n",
    "    top_k=None,\n",
    "    ignore_summaries=None,\n",
    "    do_not_summarize=False,\n",
    "    verbose=False,\n",
    "):  \n",
    "    if original_coco_gt_file is not None:\n",
    "        coco_gt = COCO(annotation_file=original_coco_gt_file, verbose=verbose)\n",
    "        coco_gt = coco_gt.loadRes(coco_gt_file)\n",
    "        check_gt_pred_match_on_file(original_coco_gt_file, coco_pred_file)\n",
    "    else:\n",
    "        coco_gt = COCO(annotation_file=coco_gt_file, verbose=verbose)\n",
    "        check_gt_pred_match_on_file(coco_gt_file, coco_pred_file)\n",
    "    coco_dt = coco_gt.loadRes(coco_pred_file)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "    coco_eval.params.verbose = verbose\n",
    "    if top_k is not None:\n",
    "        coco_eval.params.maxDets = [top_k, top_k, top_k]\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    if not do_not_summarize:\n",
    "        coco_eval.summarize(ignore_summaries=ignore_summaries)\n",
    "        perfs = coco_eval.stats\n",
    "    return coco_eval, perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a2fbc9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_file = (\n",
    "    # \"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150/sequences.txt\"\n",
    "    \"/local1/telinwu/research/resources/TREK-150/paper_data/scod_track/use_pnr_to_track_post/sequences.txt\"\n",
    ")\n",
    "results_folder = (\n",
    "    # \"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines\"\n",
    "    # \"/LTMU-H/results_scores/gpt_v2_symb_conds+defs/ope\"\n",
    "    \"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines\"\n",
    "    \"/LTMU-H/results_scores_scod/gpt_v2_use_pnr_to_track_post_oped/ope\"\n",
    "    # \"/LTMU-H/results_scores_scod/gpt_v2_use_pnr_to_track_post/ope\"\n",
    ")\n",
    "gt_folder = (\n",
    "    # \"/local1/bryanzhou008/jarvis/epic_kitchen/clean/fpv-tracking-baselines/LTMU-H/TREK-150/\"\n",
    "    \"/local1/telinwu/research/resources/TREK-150/paper_data/scod_track/use_pnr_to_track_post/clips\"\n",
    ")\n",
    "\n",
    "video_ids = open(sequences_file).readlines()\n",
    "video_ids = [s.strip() for s in video_ids]\n",
    "\n",
    "annot_idx = 0\n",
    "annotations = []\n",
    "images = []\n",
    "all_preds = []\n",
    "categories = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"object_of_change\", \n",
    "        \"supercategory\": \"object\",\n",
    "    }\n",
    "]\n",
    "\n",
    "for video_id in video_ids:\n",
    "    res_file_path = os.path.join(results_folder, \"{}.txt\".format(video_id))\n",
    "    if not os.path.exists(res_file_path):\n",
    "        continue\n",
    "    pred_bboxes = open(res_file_path).readlines()\n",
    "    pred_bboxes = [x.strip() for x in pred_bboxes][1:]\n",
    "    \n",
    "    gt_file = os.path.join(gt_folder, video_id, \"groundtruth_rect.txt\")\n",
    "    \n",
    "    gt_bboxes = open(gt_file).readlines()\n",
    "    gt_bboxes = [x.strip() for x in gt_bboxes][1:]\n",
    "    \n",
    "    for idx in range(len(gt_bboxes)):\n",
    "        gt_bbox = gt_bboxes[idx]\n",
    "        gt_bbox = [float(x) for x in gt_bbox.split(\",\")]\n",
    "        pred_bbox = pred_bboxes[idx]\n",
    "        pred_bbox = [float(x) for x in pred_bbox.split(\",\")]\n",
    "        \n",
    "        images.append({\n",
    "            \"file_name\": \"xxx.jpg\",\n",
    "            \"height\": 1080,\n",
    "            \"width\": 1920,\n",
    "            \"id\": annot_idx,\n",
    "        })\n",
    "        \n",
    "        annotations.append({\n",
    "            \"area\": gt_bbox[2] * gt_bbox[3],\n",
    "            \"iscrowd\": 0,\n",
    "            \"ignore\": 0,\n",
    "            \"bbox\": gt_bbox,\n",
    "            \"image_id\": annot_idx,\n",
    "            \"category_id\": 1,\n",
    "            \"id\": annot_idx,\n",
    "        })\n",
    "\n",
    "        pred_dict = {\n",
    "            \"image_id\": annot_idx,\n",
    "            \"category_id\": 1,\n",
    "            \"bbox\": pred_bbox,\n",
    "            \"score\": 1.0,\n",
    "        }\n",
    "        all_preds.append(pred_dict)\n",
    "        annot_idx += 1\n",
    "    pass\n",
    "\n",
    "gt_data = {\n",
    "    \"categories\": categories,\n",
    "    \"images\": images,\n",
    "    \"annotations\": annotations,\n",
    "}\n",
    "\n",
    "json.dump(\n",
    "    gt_data,\n",
    "    open(\"./tmp/trek_tmp_gt.json\", \"w\"),\n",
    "    indent=4,\n",
    ")\n",
    "\n",
    "json.dump(\n",
    "    all_preds,\n",
    "    open(\"./tmp/trek_tmp_pred.json\", \"w\"),\n",
    "    indent=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2f931047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GT and Pred files matching...\n",
      "Checking complete!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.0989\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.2088\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.0839\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.2781\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.2781\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.2781\n"
     ]
    }
   ],
   "source": [
    "coco_gt_file = (\n",
    "    \"./tmp/trek_tmp_gt.json\"\n",
    ")\n",
    "coco_pred_file = (\n",
    "    \"./tmp/trek_tmp_pred.json\"\n",
    ")\n",
    "\n",
    "ignore_summaries = {\n",
    "    \"area\": [\"small\", \"medium\", \"large\"],\n",
    "}\n",
    "coco_eval = naive_ego4d_scod_coco_results(\n",
    "    coco_gt_file=coco_gt_file,\n",
    "    coco_pred_file=coco_pred_file,\n",
    "    top_k=None,\n",
    "    ignore_summaries=ignore_summaries,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d94687",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
